# 16일차 (scikit-learn 머신 러닝)

총 정리

1. 컴퓨터 : H/W + S/W
* H/W : CPU, RAM, SSD(HDD), GPU(그래픽카드)	
* S/W : OS (Unix, Linux, Windows, Mac)
* Windows : 개인용, 업무용, 서버용



2. 파이썬과 기초통계

* 컴파일러(c/c++, java), 인터프리터(스트립트)
* 파이썬 문법 (자료구조, 리스트/튜플, 딕셔너리)
* Database : Oracle, SQL Server, MySQL(Mariadb)
* DBMS, DB, Table, Column, Row(Record), Primary Key(PK)
* SQL : SELECT, INSERT/DELETE/UPDATA, CREATE/DROP/ALTER,GRANT/REVOKE
* Python <----> DB 연동 (파일처리)
* 리스트 조작(*), 2차 리스트 
* 함수(=메소드), 전역 변수 활용(m_xxx : 전역 변수 형태)
* GUI 프로그래밍, Menu, 아이콘 
* 파일처리, 객제지향
* 컴퓨터 비전, 알고리즘, 프로그래밍 기법



3. 파이썬 라이브러리

- numpy, matplotlib, pandas(엑셀, DB테이블)



4. scikit-learn 머신 러닝

* 데이터 준비, 정제, 분석
* 분류기 선택 (머신러닝 알고리즘)
* 훈련 : 시간
* 결과 (모델) ----> 저장
* 예측, (정답률)



5. 저장된 모델을 활용

- 컴퓨터 비전 : 직접 구현, Pillow, OpenCV(*)
- MNIST --> 직접 훈련 --> 결과 예측 (GUI)
- 하르케스케이드 --> 얼굴인식 (저장된 모델) ==> OpenCV랑 연결
  ----> 얼굴, 입, 코, 고양이~~~~
- MibileNETSSD --> 사물인식 모델
  --> CAFFE 형식으로 제공 --> OpenCV 최신버전에서 로딩 가능



## 컴퓨터 비전(딥러닝) OpenCV - 사물인식(정지 영상)

```python
def deep1OpenCV() :
    global window, canvas, paper, filename, inImage, outImage, inH, inW, outH, outW
    global photo, cvPhoto
    if inImage == None:
        return
    cvPhoto2 = cvPhoto[:] #OpenCV 개체
    ######### 고정해서 쓸 코드 ############
    CONF_VALUE= 0.2 # args["confidence"] : 샘플 돌렸을 때 기본 값이 0.2
    CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat",
        "bottle", "bus", "car", "cat", "chair", "cow", "diningtable",
        "dog", "horse", "motorbike", "person", "pottedplant", "sheep",
        "sofa", "train", "tvmonitor"]
    COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))
    net = cv2.dnn.readNetFromCaffe("MobileNetSSD_deploy.prototxt.txt", "MobileNetSSD_deploy.caffemodel")
    image = cvPhoto2
    (h, w) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)
    net.setInput(blob)
    detections = net.forward()

    # loop over the detections
    for i in np.arange(0, detections.shape[2]):
        # extract the confidence (i.e., probability) associated with the
        # prediction
        confidence = detections[0, 0, i, 2]
        if confidence > CONF_VALUE:
            idx = int(detections[0, 0, i, 1])
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")
            # display the prediction
            label = "{}: {:.2f}%".format(CLASSES[idx], confidence * 100)
            print("[INFO] {}".format(label))
            cv2.rectangle(image, (startX, startY), (endX, endY),
                COLORS[idx], 2)
            y = startY - 15 if startY - 15 > 15 else startY + 15
            cv2.putText(image, label, (startX, y),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)
    cvPhoto2 = image
#########################
    # 화면 출력
    photo2 = Image.fromarray(cvPhoto2)
    toColorOutArray(photo2)
```



## 컴퓨터 비전(딥러닝) OpenCV - 사물인식(동영상)

```python
def deep2OpenCV() :
    global window, canvas, paper, filename, inImage, outImage, inH, inW, outH, outW
    global photo, cvPhoto, frame
    filename = askopenfilename(parent=window, filetypes=(("동영상 파일", "*.mp4"), ("모든파일", "*.*")))
    if filename == '' or filename == None:
        return
    cap = cv2.VideoCapture(filename) # filename 대신 0쓰면 연결된 카메라의 실시간 영상 출력
    s_factor = 0.5 # 화면 크기 비율, 개인적으로 조절 가능

######### 고정해서 쓸 코드 ############
    frameCount = 0 # 영상의 장면 수
    while TRUE : # 반복 수 모를 때
        ret, frame = cap.read() # ret:return을 나타내는 것으로 T,F 값 출력
        if not ret : # 영상이 끝나면 멈춰라
            break
        frameCount += 1
        if frameCount % 8 == 0 : # 8은 화면 속도 조절 화면을 뛰어넘기는 초 값으로 너무 느리면 값을 키우면 되지만 장면을 많이 뛰어넘길 수 있음.
            frame = cv2.resize(frame,None,fx = s_factor, fy=s_factor, interpolation=cv2.INTER_AREA) # 한장씩 캡처한 것
            ######### 고정해서 쓸 코드 ############
            CONF_VALUE= 0.2 # args["confidence"] : 샘플 돌렸을 때 기본 값이 0.2
            CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat",
                "bottle", "bus", "car", "cat", "chair", "cow", "diningtable",
                "dog", "horse", "motorbike", "person", "pottedplant", "sheep",
                "sofa", "train", "tvmonitor"]
            COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))
            net = cv2.dnn.readNetFromCaffe("MobileNetSSD_deploy.prototxt.txt", "MobileNetSSD_deploy.caffemodel")
            image = frame
            (h, w) = image.shape[:2]
            blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)
            net.setInput(blob)
            detections = net.forward()

            # loop over the detections
            for i in np.arange(0, detections.shape[2]):
                # extract the confidence (i.e., probability) associated with the
                # prediction
                confidence = detections[0, 0, i, 2]
                if confidence > CONF_VALUE:
                    idx = int(detections[0, 0, i, 1])
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    (startX, startY, endX, endY) = box.astype("int")
                    # display the prediction
                    label = "{}: {:.2f}%".format(CLASSES[idx], confidence * 100)
                    print("[INFO] {}".format(label))
                    cv2.rectangle(image, (startX, startY), (endX, endY),
                        COLORS[idx], 2)
                    y = startY - 15 if startY - 15 > 15 else startY + 15
                    cv2.putText(image, label, (startX, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)
            frame = image
        #########################
            cv2.imshow('Deep Learning', frame)
            c = cv2.waitKey(1)
            if c == 27 : # ESC 키
                break
            elif c == ord('c') or c == ord('C') :
                captureVideo()
                window.update() # 캡처 화면을 툴에 출력 시켜라

    cap.release()
    cv2.destroyAllWindows()

def captureVideo() :
    global window, canvas, paper, filename, inImage, outImage, inH, inW, outH, outW
    global photo, cvPhoto, frame
    loadImageColor(frame) # frame 자체를 load 시켜서 로딩
    equalImageColor()
```



- 영상이 어두워서 결과가 잘 안나올 경우, 평활화해서 영상을 출력할 경우 더 잘나올 수 있음
- 사람이 제일 많이 나오는 경우, 병이 가장 많이 나오는 경우 등과 같은 결과를 도출 할 수 있음

--------------------------------------------------------------------

## 미션(16일차) <심화>

- 딥러닝 활용 컴퓨터 비전 --> 002.mp4(쇼생크)

```python
def deep2OpenCV() :
    global window, canvas, paper, filename, inImage, outImage, inH, inW, outH, outW
    global photo, cvPhoto, frame, maxCount
    filename = askopenfilename(parent=window, filetypes=(("동영상 파일", "*.mp4"), ("모든파일", "*.*")))
    if filename == '' or filename == None:
        return
    cap = cv2.VideoCapture(filename) # filename 대신 0쓰면 연결된 카메라의 실시간 영상 출력
    s_factor = 0.5 # 화면 크기 비율, 개인적으로 조절 가능

######### 고정해서 쓸 코드 ############
    maxCount = 0
    PC=[]
    frameCount = 0 # 영상의 장면 수
    while TRUE : # 반복 수 모를 때
        ret, frame = cap.read() # ret:return을 나타내는 것으로 T,F 값 출력
        if not ret : # 영상이 끝나면 멈춰라
            break
        frameCount += 1
        if frameCount % 8 == 0 : # 8은 화면 속도 조절 화면을 뛰어넘기는 초 값으로 너무 느리면 값을 키우면 되지만 장면을 많이 뛰어넘길 수 있음.
            frame = cv2.resize(frame,None,fx = s_factor, fy=s_factor, interpolation=cv2.INTER_AREA) # 한장씩 캡처한 것
            ######### 고정해서 쓸 코드 ############
            CONF_VALUE= 0.2 # args["confidence"] : 샘플 돌렸을 때 기본 값이 0.2
            CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat",
                "bottle", "bus", "car", "cat", "chair", "cow", "diningtable",
                "dog", "horse", "motorbike", "person", "pottedplant", "sheep",
                "sofa", "train", "tvmonitor"]
            COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))
            net = cv2.dnn.readNetFromCaffe("MobileNetSSD_deploy.prototxt.txt", "MobileNetSSD_deploy.caffemodel")
            image = frame
            (h, w) = image.shape[:2]
            blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)
            net.setInput(blob)
            detections = net.forward()
            # loop over the detections
            pCount = 0
            for i in np.arange(0, detections.shape[2]):
                # extract the confidence (i.e., probability) associated with the
                # prediction
                confidence = detections[0, 0, i, 2]
                if confidence > CONF_VALUE:
                    idx = int(detections[0, 0, i, 1])
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    (startX, startY, endX, endY) = box.astype("int")
                    # display the prediction
                    label = "{}: {:.2f}%".format(CLASSES[idx], confidence * 100)
                    # print("[INFO] {}".format(label))
                    if CLASSES[idx] == 'person' :
                        pCount+=1
                        # print(pCount)
                        PC.append(pCount)
                        # print(max(PC))
                    cv2.rectangle(image, (startX, startY), (endX, endY),
                        COLORS[idx], 2)
                    y = startY - 15 if startY - 15 > 15 else startY + 15
                    cv2.putText(image, label, (startX, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)
            frame = image
        #########################
            cv2.imshow('Deep Learning', frame)
            c = cv2.waitKey(1)
            if c == 27 : # ESC 키
                break
            elif maxCount < pCount :
                maxCount = pCount
                status = Label(window, text="최대 인원 : "+ str(maxCount)+"명", bd=1, relief=SUNKEN, anchor=W)
                # print("최대 인원:"+ str(maxCount))
                captureVideo()
                window.update() # 캡처 화면을 툴에 출력 시켜라

    status.pack(side=BOTTOM, fill=X)
    cap.release()
    cv2.destroyAllWindows()

def captureVideo() :
    global window, canvas, paper, filename, inImage, outImage, inH, inW, outH, outW
    global photo, cvPhoto, frame, maxCount
    loadImageColor(frame) # frame 자체를 load 시켜서 로딩
    equalImageColor()
```



- 최대 사람이 출연한 화면을 캡처 (최대인원,정답률) ==> ?
- 평활화 처리를 추가한 동영상 인식 ==> ?
- 내부적으로만 평활화하고, 보이는 것은 원영상
- 최대 출연자 화면에서 각 출연자마다 사람을 저장하기
- 출연자마다 저장되기 전에, 얼굴인식 하기

또는 미니 프로젝트 진행