{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Python is an interpreted, high-level, general-purpose programming language.',\n",
       " \"Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\",\n",
       " 'Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.',\n",
       " '[27] Python is dynamically typed and garbage-collected.',\n",
       " 'It supports multiple programming paradigms, including procedural, object-oriented, and functional programming.',\n",
       " \"Python is often described as a 'batteries included' language due to its comprehensive standard library.\",\n",
       " '[28]']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import *\n",
    "from nltk.stem import *\n",
    "from konlpy.tag import Kkma\n",
    "from nltk.tokenize import *\n",
    "from nltk.tag import *\n",
    "import nltk\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras import *\n",
    "from keras.datasets import mnist\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "\n",
    "text=\"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[27] Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a 'batteries included' language due to its comprehensive standard library.[28]\"\n",
    "text=sent_tokenize(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['python', 'interpreted', 'high-level', 'general-purpose', 'programming', 'language'], ['created', 'guido', 'van', 'rossum', 'first', 'released', '1991', 'python', 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'notable', 'use', 'significant', 'whitespace'], ['language', 'constructs', 'object-oriented', 'approach', 'aim', 'help', 'programmers', 'write', 'clear', 'logical', 'code', 'small', 'large-scale', 'projects'], ['python', 'dynamically', 'typed', 'garbage-collected'], ['supports', 'multiple', 'programming', 'paradigms', 'including', 'procedural', 'object-oriented', 'functional', 'programming'], ['python', 'often', 'described', \"'batteries\", 'included', 'language', 'due', 'comprehensive', 'standard', 'library'], []]\n"
     ]
    }
   ],
   "source": [
    "voc=Counter()\n",
    "sentences = []\n",
    "stop_words = stopwords.words('english')\n",
    "for i in text:\n",
    "    sentence=word_tokenize(i)\n",
    "    res = []\n",
    "    for word in sentence: \n",
    "        word=word.lower()\n",
    "        if word not in stop_words: \n",
    "            if len(word) > 2:\n",
    "                res.append(word)\n",
    "                voc[word]=voc[word]+1\n",
    "    sentences.append(res) \n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'python': 4,\n",
       "         'interpreted': 1,\n",
       "         'high-level': 1,\n",
       "         'general-purpose': 1,\n",
       "         'programming': 3,\n",
       "         'language': 3,\n",
       "         'created': 1,\n",
       "         'guido': 1,\n",
       "         'van': 1,\n",
       "         'rossum': 1,\n",
       "         'first': 1,\n",
       "         'released': 1,\n",
       "         '1991': 1,\n",
       "         'design': 1,\n",
       "         'philosophy': 1,\n",
       "         'emphasizes': 1,\n",
       "         'code': 2,\n",
       "         'readability': 1,\n",
       "         'notable': 1,\n",
       "         'use': 1,\n",
       "         'significant': 1,\n",
       "         'whitespace': 1,\n",
       "         'constructs': 1,\n",
       "         'object-oriented': 2,\n",
       "         'approach': 1,\n",
       "         'aim': 1,\n",
       "         'help': 1,\n",
       "         'programmers': 1,\n",
       "         'write': 1,\n",
       "         'clear': 1,\n",
       "         'logical': 1,\n",
       "         'small': 1,\n",
       "         'large-scale': 1,\n",
       "         'projects': 1,\n",
       "         'dynamically': 1,\n",
       "         'typed': 1,\n",
       "         'garbage-collected': 1,\n",
       "         'supports': 1,\n",
       "         'multiple': 1,\n",
       "         'paradigms': 1,\n",
       "         'including': 1,\n",
       "         'procedural': 1,\n",
       "         'functional': 1,\n",
       "         'often': 1,\n",
       "         'described': 1,\n",
       "         \"'batteries\": 1,\n",
       "         'included': 1,\n",
       "         'due': 1,\n",
       "         'comprehensive': 1,\n",
       "         'standard': 1,\n",
       "         'library': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('python', 4), ('interpreted', 1), ('high-level', 1), ('general-purpose', 1), ('programming', 3), ('language', 3), ('created', 1), ('guido', 1), ('van', 1), ('rossum', 1), ('first', 1), ('released', 1), ('1991', 1), ('design', 1), ('philosophy', 1), ('emphasizes', 1), ('code', 2), ('readability', 1), ('notable', 1), ('use', 1), ('significant', 1), ('whitespace', 1), ('constructs', 1), ('object-oriented', 2), ('approach', 1), ('aim', 1), ('help', 1), ('programmers', 1), ('write', 1), ('clear', 1), ('logical', 1), ('small', 1), ('large-scale', 1), ('projects', 1), ('dynamically', 1), ('typed', 1), ('garbage-collected', 1), ('supports', 1), ('multiple', 1), ('paradigms', 1), ('including', 1), ('procedural', 1), ('functional', 1), ('often', 1), ('described', 1), (\"'batteries\", 1), ('included', 1), ('due', 1), ('comprehensive', 1), ('standard', 1), ('library', 1)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 4),\n",
       " ('programming', 3),\n",
       " ('language', 3),\n",
       " ('code', 2),\n",
       " ('object-oriented', 2),\n",
       " ('interpreted', 1),\n",
       " ('high-level', 1),\n",
       " ('general-purpose', 1),\n",
       " ('created', 1),\n",
       " ('guido', 1),\n",
       " ('van', 1),\n",
       " ('rossum', 1),\n",
       " ('first', 1),\n",
       " ('released', 1),\n",
       " ('1991', 1),\n",
       " ('design', 1),\n",
       " ('philosophy', 1),\n",
       " ('emphasizes', 1),\n",
       " ('readability', 1),\n",
       " ('notable', 1),\n",
       " ('use', 1),\n",
       " ('significant', 1),\n",
       " ('whitespace', 1),\n",
       " ('constructs', 1),\n",
       " ('approach', 1),\n",
       " ('aim', 1),\n",
       " ('help', 1),\n",
       " ('programmers', 1),\n",
       " ('write', 1),\n",
       " ('clear', 1),\n",
       " ('logical', 1),\n",
       " ('small', 1),\n",
       " ('large-scale', 1),\n",
       " ('projects', 1),\n",
       " ('dynamically', 1),\n",
       " ('typed', 1),\n",
       " ('garbage-collected', 1),\n",
       " ('supports', 1),\n",
       " ('multiple', 1),\n",
       " ('paradigms', 1),\n",
       " ('including', 1),\n",
       " ('procedural', 1),\n",
       " ('functional', 1),\n",
       " ('often', 1),\n",
       " ('described', 1),\n",
       " (\"'batteries\", 1),\n",
       " ('included', 1),\n",
       " ('due', 1),\n",
       " ('comprehensive', 1),\n",
       " ('standard', 1),\n",
       " ('library', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_sorted=sorted(voc.items(),key=lambda a:a[1], reverse=True)\n",
    "voc_sorted\n",
    "\n",
    "# res={} # 빈도수가 2이상인 데이터 저장\n",
    "# i=0\n",
    "# for (w,f) in voc_sorted:\n",
    "#     if f > 1:\n",
    "#         i+=1\n",
    "#         res[w]=i\n",
    "# print(res) # 번호는 인덱스를 의미 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras를 활용한 문자열 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 문자열 처리\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tok=Tokenizer() # 객체 생성\n",
    "tok.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'python': 2, 'is': 3, 'programming': 4, 'language': 5, 'its': 6, 'code': 7, 'object': 8, 'oriented': 9, 'to': 10, 'an': 11, 'interpreted': 12, 'high': 13, 'level': 14, 'general': 15, 'purpose': 16, 'created': 17, 'by': 18, 'guido': 19, 'van': 20, 'rossum': 21, 'first': 22, 'released': 23, 'in': 24, '1991': 25, \"python's\": 26, 'design': 27, 'philosophy': 28, 'emphasizes': 29, 'readability': 30, 'with': 31, 'notable': 32, 'use': 33, 'of': 34, 'significant': 35, 'whitespace': 36, 'constructs': 37, 'approach': 38, 'aim': 39, 'help': 40, 'programmers': 41, 'write': 42, 'clear': 43, 'logical': 44, 'for': 45, 'small': 46, 'large': 47, 'scale': 48, 'projects': 49, '27': 50, 'dynamically': 51, 'typed': 52, 'garbage': 53, 'collected': 54, 'it': 55, 'supports': 56, 'multiple': 57, 'paradigms': 58, 'including': 59, 'procedural': 60, 'functional': 61, 'often': 62, 'described': 63, 'as': 64, 'a': 65, \"'batteries\": 66, \"included'\": 67, 'due': 68, 'comprehensive': 69, 'standard': 70, 'library': 71, '28': 72}\n"
     ]
    }
   ],
   "source": [
    "# 단어 단위로 인덱스와 함께 출력\n",
    "print(tok.word_index) # 정렬(빈도수)-> 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('python', 3), ('is', 3), ('an', 1), ('interpreted', 1), ('high', 1), ('level', 1), ('general', 1), ('purpose', 1), ('programming', 3), ('language', 3), ('created', 1), ('by', 1), ('guido', 1), ('van', 1), ('rossum', 1), ('and', 5), ('first', 1), ('released', 1), ('in', 1), ('1991', 1), (\"python's\", 1), ('design', 1), ('philosophy', 1), ('emphasizes', 1), ('code', 2), ('readability', 1), ('with', 1), ('its', 3), ('notable', 1), ('use', 1), ('of', 1), ('significant', 1), ('whitespace', 1), ('constructs', 1), ('object', 2), ('oriented', 2), ('approach', 1), ('aim', 1), ('to', 2), ('help', 1), ('programmers', 1), ('write', 1), ('clear', 1), ('logical', 1), ('for', 1), ('small', 1), ('large', 1), ('scale', 1), ('projects', 1), ('27', 1), ('dynamically', 1), ('typed', 1), ('garbage', 1), ('collected', 1), ('it', 1), ('supports', 1), ('multiple', 1), ('paradigms', 1), ('including', 1), ('procedural', 1), ('functional', 1), ('often', 1), ('described', 1), ('as', 1), ('a', 1), (\"'batteries\", 1), (\"included'\", 1), ('due', 1), ('comprehensive', 1), ('standard', 1), ('library', 1), ('28', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(tok.word_counts) # 정렬(빈도수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 11, 12, 13, 14, 15, 16, 4, 5], [17, 18, 19, 20, 21, 1, 22, 23, 24, 25, 26, 27, 28, 29, 7, 30, 31, 6, 32, 33, 34, 35, 36], [6, 5, 37, 1, 8, 9, 38, 39, 10, 40, 41, 42, 43, 44, 7, 45, 46, 1, 47, 48, 49], [50, 2, 3, 51, 52, 1, 53, 54], [55, 56, 57, 4, 58, 59, 60, 8, 9, 1, 61, 4], [2, 3, 62, 63, 64, 65, 66, 67, 5, 68, 10, 6, 69, 70, 71], [72]]\n"
     ]
    }
   ],
   "source": [
    "print(tok.texts_to_sequences(text)) # tok.word_index의 인덱스를 가지고 원래는 문장 순서대로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'interpreted',\n",
       " 'high',\n",
       " 'level',\n",
       " 'general',\n",
       " 'purpose',\n",
       " 'created',\n",
       " 'by',\n",
       " 'guido',\n",
       " 'van',\n",
       " 'rossum',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1991',\n",
       " \"python's\",\n",
       " 'design',\n",
       " 'philosophy',\n",
       " 'emphasizes',\n",
       " 'readability',\n",
       " 'with',\n",
       " 'notable',\n",
       " 'use',\n",
       " 'of',\n",
       " 'significant',\n",
       " 'whitespace',\n",
       " 'constructs',\n",
       " 'approach',\n",
       " 'aim',\n",
       " 'help',\n",
       " 'programmers',\n",
       " 'write',\n",
       " 'clear',\n",
       " 'logical',\n",
       " 'for',\n",
       " 'small',\n",
       " 'large',\n",
       " 'scale',\n",
       " 'projects',\n",
       " '27',\n",
       " 'dynamically',\n",
       " 'typed',\n",
       " 'garbage',\n",
       " 'collected',\n",
       " 'it',\n",
       " 'supports',\n",
       " 'multiple',\n",
       " 'paradigms',\n",
       " 'including',\n",
       " 'procedural',\n",
       " 'functional',\n",
       " 'often',\n",
       " 'described',\n",
       " 'as',\n",
       " 'a',\n",
       " \"'batteries\",\n",
       " \"included'\",\n",
       " 'due',\n",
       " 'comprehensive',\n",
       " 'standard',\n",
       " 'library',\n",
       " '28']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.word_counts.items()\n",
    "# words_freq=빈도수가 2보다 작은 단어들을 저장\n",
    "words_freq=[w for w,c in tok.word_counts.items() if c<2]\n",
    "words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for w in words_freq:\n",
    "    print(tok.word_index[w]) # 각 단어 인덱스\n",
    "    print(tok.word_counts[w]) # 각 단어 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5], [1, 7, 6], [6, 5, 1, 8, 9, 10, 7, 1], [2, 3, 1], [4, 8, 9, 1, 4], [2, 3, 5, 10, 6], []]\n",
      "==============================\n",
      "{'and': 1, 'python': 2, 'is': 3, 'programming': 4, 'language': 5, 'its': 6, 'code': 7, 'object': 8, 'oriented': 9, 'to': 10}\n"
     ]
    }
   ],
   "source": [
    "for w in words_freq:\n",
    "    del tok.word_index[w] # 각 단어 인덱스\n",
    "    del tok.word_counts[w] # 각 단어 빈도수\n",
    "print(tok.texts_to_sequences(text))\n",
    "print(\"=\"*30)\n",
    "print(tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java', 3), ('ds', 2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=['java','python','ds','ds','java','java']\n",
    "from nltk import FreqDist\n",
    "fd=FreqDist(words)\n",
    "fd.N()\n",
    "fd.freq('java') # 0.5 확률\n",
    "fd['ds'] # 단어 2번 등장\n",
    "fd.most_common(1) # 가장 빈도수가 높은 단어 추출\n",
    "fd.most_common(2) # 가장 빈도수가 높은 2개 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '는', '자연어', '자연어', '처리', '를', '공부', '하고', '있습니다']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot 인코딩\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "tok=okt.morphs(\"나는 자연어 자연어 처리를 공부하고 있습니다\")\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '공부': 5, '하고': 6, '있습니다': 7}\n"
     ]
    }
   ],
   "source": [
    "word2Idx={}\n",
    "for t in tok:\n",
    "    if t not in word2Idx.keys():\n",
    "        word2Idx[t] = len(word2Idx)\n",
    "print(word2Idx)\n",
    "# 중복된 단어는 추가 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자열 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def ohe(w,word2Idx):\n",
    "    ohv=[0]*len(word2Idx)\n",
    "    p=word2Idx[w]\n",
    "    ohv[p]=1\n",
    "    return ohv\n",
    "print(ohe(\"공부\", word2Idx)) # 000000100 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 원핫인코딩\n",
    "text=\"오늘 메뉴는 뼈다귀 해장국입니다. 맛있게 먹어요. 국산이래요. 뼈다귀 최고 뼈다귀 최고\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'뼈다귀': 1,\n",
       " '최고': 2,\n",
       " '오늘': 3,\n",
       " '메뉴는': 4,\n",
       " '해장국입니다': 5,\n",
       " '맛있게': 6,\n",
       " '먹어요': 7,\n",
       " '국산이래요': 8}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "tok=Tokenizer()\n",
    "tok.fit_on_texts([text])\n",
    "tok.word_counts\n",
    "tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 6, 7]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2=\"뼈다귀 관련 음식을 가장 맛있게 먹어요\"\n",
    "res=tok.texts_to_sequences([text2]) # text2를 기존 코퍼스에 대입해서 동일한 부분의 인덱스 출력\n",
    "res\n",
    "#res[0][1] => 6 : 요소 하나씩 참고하고 싶을 때 쓰면 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 -> 01000000\n",
    "# 6 -> 00000010\n",
    "vLen=len(tok.word_index)\n",
    "from keras.utils import to_categorical\n",
    "pres=to_categorical(res, num_classes=vLen+1) \n",
    "# to_categorical함수는 0부터 시작하는데 데이터에는 0이 없어 하나 추가하기\n",
    "pres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원핫인코딩 문제점\n",
    "1) 음식, 식사, 점심, 날씨 => 원핫인코딩 => 크기:4\n",
    "    => 단어들간에 유사한 정도를 나타내기 어려움\n",
    "    \n",
    "2) 공간을 많이 차지(sparse matrix => dense matrix 변환 필요) \n",
    "\n",
    "3) 연관검색어 표현이 어려움. ex) '뼈다귀' => '뼈다귀 해장국', '뼈다귀 국물', '뼈다귀 감자탕'...  \n",
    "    => 해결하기 위한 여러가지 노력(ing)=>LSA, Word2Vec...  \n",
    "    => LSA:카운트 기반으로 단어의 의미를 벡터화 하는 알고리즘  \n",
    "    => Word2Vec:단어를 벡터 공간으로 표현(거리)  \n",
    "    => Seq2Seq, RNNLM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어 모델?\n",
    "# Vocabulary: 기계가 학습한 단어의 집합\n",
    "# out of Vocabulary(OOV) : 기계가 학습 안한 단어들\n",
    "# => BPE, WPM 알고리즘(데이터 전처리)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPE : 연속으로 가장 많이 등장한 글자의 쌍 => 한 글자로 표현(변환)  \n",
    "   - 문자열 : aaabadaaabac   \n",
    "      Z=aa  \n",
    "   - 문자열 : ZabadZabac  \n",
    "      Y=ab\n",
    "   - 문자열 : ZYadZYac\n",
    "      X=ZY\n",
    "   - 문자열 : XadXac\n",
    "      W=Xa\n",
    "   - 문자열 : WdWc\n",
    "------------------------------------------\n",
    "- 허프만 인코딩(트리)가 효율 짱 좋음  \n",
    "    {'low':5, 'lower':2, 'newest':6, 'widest':3}  \n",
    "    (단어 : 빈도수,...}  \n",
    "-------------------------------------------\n",
    "- BPE 알고리즘 사용 -> OOV에 대한 문제점 해결  \n",
    "     food : 의미를 이해할 수 없음\n",
    "     lowest : 의미를 이해할 수 있음 (by BPE)  \n",
    "※ KMP, 보이어무어, 레벤슈타인 거리 등 검색  \n",
    "1) 모든 단어들을 글자로 분리   \n",
    "    {'l o w': 5, 'l o w e r' : 2, 'n e w e s t':6, 'w i d e s t' : 3} => 빈도수   \n",
    "    -> l,o,w,e,r,n,w,s,t,i,d   \n",
    "2) 빈도가 가장 높은 문자들의 쌍을 검색  \n",
    "    -> es가 가장 많이 등장(9번) => es를 묶음  \n",
    "    {'l o w': 5, 'l o w e r' : 2, 'n e w es t':6, 'w i d es t' : 3}\n",
    "    -> l,o,w,e,r,n,w,s,t,i,d,es\n",
    "3) 빈도가 가장 높은 문자들의 쌍을 검색  \n",
    "    -> es t가 가장 많이 등장(9번) => est를 묶음  \n",
    "    {'l o w': 5, 'l o w e r' : 2, 'n e w est':6, 'w i d est' : 3}  \n",
    "    -> l,o,w,e,r,n,w,s,t,i,d,es,est  \n",
    "4) 빈도가 가장 높은 문자들의 쌍을 검색    \n",
    "    -> l o 가 가장 많이 등장(7번) => lo를 묶음    \n",
    "    {'l o w': 5, 'l o w e r' : 2, 'n e w est':6, 'w i d est' : 3}  \n",
    "    -> l,o,w,e,r,n,w,s,t,i,d,es,est, lo  \n",
    "\n",
    "=> 위 과정을 반복...(10번)   \n",
    "    -> l,o,w,e,r,n,s,t,i,d,  \n",
    "    -> 9번 등장 : es,est,   \n",
    "    -> 7번 등장 : lo, low,   \n",
    "    -> 6번 등장 : ne, new, newest,   \n",
    "    -> 3번 등장 : wi, wid, widest...   \n",
    "    \n",
    "- 'lowest'란 단어가 등장한다면,기계는 우선 'lowest'를 전부 글자 단위로 분할. 즉, 'l, o, w, e, s, t'가 됨.   \n",
    "그리고 기계는 위의 단어 집합을 참고로 하여 'low'와 'est'를 찾아냄.  \n",
    "단어를 찾는건 앞 또는 뒤에서부터 찾아도 됨.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BFE 알고리즘 구현(연습문제)\n",
    "# 2. 상품분류(10가지) 미니 프로젝트 \n",
    "# gspark@kw.ac.kr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
