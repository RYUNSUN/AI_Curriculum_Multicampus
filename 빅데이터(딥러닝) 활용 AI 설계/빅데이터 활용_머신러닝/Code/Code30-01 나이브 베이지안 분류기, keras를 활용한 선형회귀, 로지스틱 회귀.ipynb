{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 베이지안 필터기 -> 부/긍정 평가  \n",
    "      => 네이버 영화 평가\n",
    "#### 2. IMDB -> 추천시스템\n",
    "#### 3. 조건부확률  \n",
    "    비가 내리는 날에 교통사고 발생될 확률 => P(교통사고 | 비)  \n",
    "#### 4. 베이즈 정리  \n",
    "    전체 손님 수 : 100  \n",
    "    노트 구매 : 50  \n",
    "    펜 구매 : 20  \n",
    "    두 가지 모두 구매 : 10  \n",
    "\n",
    "    노트, 펜 모두 구매할 확률?  \n",
    "    50/100 * 10/50 => 1/10  \n",
    "    20/100 * 10/20 => 1/10  \n",
    "\n",
    "    A와 B의 결합확률 = P(A|B)*P(B)\n",
    "\n",
    "#### 5. 나이브베이즈 분류기 \n",
    "    : 베이즈 정리를 기반으로 작성된 분류기   \n",
    "    A:입력테스트, B:카테고리(스팸/햄)  \n",
    "    =>   \n",
    "    P(B|A) => 여러개 카테고리지만 입력테스트는 동일\n",
    "\n",
    "    ex)  \n",
    "    P(스팸|나이트, 형님, 강호동,...) : 나이트라는 텍스트가 스팸, 햄 모두에 들어간다는 의미  \n",
    "    P(햄|나이트)   \n",
    "    => 나이트는 모두 들어가므로 수식에서 빼도 됨   \n",
    "    P(B|A) => 여러개 카테고리지만 입력테스트는 동일   \n",
    "    : P(A|B)*P(B) / P(A) => P(A|B)*P(B) (계산이 많아지니깐 P(A)를 빼고 계산하고자 함)  \n",
    "\n",
    "    P(B)는 각 카테고리로 분류될 확률  \n",
    "    P(A|B) : A는 단어들의 집합(aN)\n",
    "    P(A|B)=P(a1|B)P(a2|B)....P(aN|B)\n",
    "\n",
    "    P(aN|B)의 확률은 단어가 카테고리에 속학 확률  \n",
    "\n",
    "    정리하면, P(A|B)*P(B)를 카테고리별로 계산하면 됨  \n",
    "    P(B|A)는 각 카테고리별로 P(A|B)*P(B)을 구하고 최대값을 출력하면 됨  \n",
    "    P(카테1|나이트, 강호동, 형님) = ?\n",
    "    P(카테2|나이트, 강호동, 형님) = ?\n",
    "    P(카테3|나이트, 강호동, 형님) = ?\n",
    "    MAX???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이브 베이지안 필터기\n",
    "직접 코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFilter: # 붕어빵 기계(클래스)\n",
    "    def __init__(self): # self:자신(만들어질 객체, 붕어빵)\n",
    "        self.words=set() #붕어빵 길이 = 15센티\n",
    "        self.words_dict={} #카테고리(광고/중요) 단어 빈도수\n",
    "        self.category_dict={} \n",
    "    \n",
    "    def split(self,text): # 어미/조사/구두점 제외, 형태소 분석\n",
    "        result=[]\n",
    "        okt=Okt()\n",
    "        malist=okt.pos(text, norm=True, stem=True)\n",
    "        for word in malist:\n",
    "            if word[1] not in [\"Josa\",\"Eomi\",\"Punctuation\"]:\n",
    "                result.append(word[0])\n",
    "        return result\n",
    "            #print(word[1])\n",
    "            #조사, 어미, 구두점을 제외한 나머지 단어만\n",
    "            # result에 저장\n",
    "    \n",
    "    def inc_word(self,word, category): #파격, 광고 / 오늘, 광고\n",
    "        # 단어를 카테고리에 추가\n",
    "        if not category in self.words_dict: #{'광고:{}'}\n",
    "            self.words_dict[category]={}\n",
    "        if not word in self.words_dict[category]:\n",
    "            self.words_dict[category][word]=0 #{'광고:{'파격':0}'}\n",
    "        self.words_dict[category][word] += 1 #{'광고:{'파격':1,'오늘':1}','중요':{}}\n",
    "        self.words.add(word) #{'파격','오늘'}, words자체는 set이므로 중복이 들어가지 않음\n",
    "    \n",
    "    def inc_category(self, category):\n",
    "        if not category in self.category_dict:\n",
    "            self.category_dict[category]=0\n",
    "        self.category_dict[category]+=1\n",
    "        \n",
    "    \n",
    "    # 예측 \n",
    "    def predict(self,text):\n",
    "        score_list=[]\n",
    "        ad_score=1\n",
    "        im_score=1\n",
    "        word_list=self.split(text)\n",
    "        for category in self.words_dict.keys():\n",
    "            if category == \"광고\":\n",
    "                ad=self.words_dict.get(category)\n",
    "                ad_sum=sum(ad.values())\n",
    "            else:\n",
    "                important=self.words_dict.get(category)\n",
    "                important_sum=sum(important.values())\n",
    "#         print(ad, ad_sum, important,important_sum)   \n",
    "        for w in word_list:\n",
    "            for word in ad.keys():\n",
    "                if not w in word:\n",
    "                    freq=1\n",
    "                else:\n",
    "                    freq=ad[word]\n",
    "            ad_score *= freq/ad_sum\n",
    "        print(ad_score)\n",
    "        \n",
    "        for w in word_list:\n",
    "            for word in important.keys():\n",
    "                if not w in word:\n",
    "                    freq=1\n",
    "                else:\n",
    "                    freq=ad[word]\n",
    "            im_score *= freq/important_sum\n",
    "        print(im_score)\n",
    "        scorelist.append()\n",
    "                    \n",
    "    def fit(self,text,category):\n",
    "        word_list=self.split(text)\n",
    "        for word in word_list:\n",
    "            self.inc_word(word,category)\n",
    "        self.inc_category(category)\n",
    "#         print(word_list)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.432264881050256e-07\n",
      "5.141890467449261e-06\n"
     ]
    }
   ],
   "source": [
    "bs=BayesianFilter() # 붕어빵 기계에서 붕어빵 1개 만들어라\n",
    "bs.fit(\"파격세일 - 오늘까지만 50% 할인\",\"광고\")\n",
    "bs.fit(\"무료 쿠폰 선물 & 무료 배송\",\"광고\")\n",
    "bs.fit(\"아사히 맥주 세일\",\"광고\")\n",
    "bs.fit(\"회의 일정 확인 부탁드립니다.\",\"중요\")\n",
    "bs.fit(\"오늘 일정이 없습니다.\",\"중요\")\n",
    "bs.fit(\"현데계 백화점 세일\", \"광고\")\n",
    "bs.fit(\"봄과 함께 찾아온 따뜻한 신제품 소식\", \"광고\")\n",
    "bs.fit(\"인기 제품 기간 한정 세일\", \"광고\")\n",
    "bs.fit(\"오늘 일정 확인\", \"중요\")\n",
    "bs.fit(\"프로젝트 진행 상황 보고\",\"중요\")\n",
    "bs.fit(\"계약 잘 부탁드립니다\",\"중요\")\n",
    "bs.fit(\"회의 일정이 등록되었습니다.\",\"중요\")\n",
    "\n",
    "bs.predict(\"재고 정리 할인, 배송\")\n",
    "# res,socrelist=bs.predict(\"재고 정리 할인, 배송\")\n",
    "# print(\"결과:\",res) # 중요 or 광고\n",
    "# print(scorelist) # 중요메일/광고메일 베이지안 필터기 각 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras 선형회귀, 로지스틱 회귀 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:02:34.601305 14200 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0812 16:02:34.609284 14200 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 466.7593 - mean_squared_error: 466.7593\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 94.6346 - mean_squared_error: 94.6346\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 884us/step - loss: 94.0721 - mean_squared_error: 94.0721\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 93.5924 - mean_squared_error: 93.5924\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 773us/step - loss: 93.1887 - mean_squared_error: 93.1887\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 92.8545 - mean_squared_error: 92.8545\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 92.5839 - mean_squared_error: 92.5839\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 92.3715 - mean_squared_error: 92.3715\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 772us/step - loss: 92.2120 - mean_squared_error: 92.2120\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 92.1008 - mean_squared_error: 92.1008\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 92.0336 - mean_squared_error: 92.0336\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 92.0062 - mean_squared_error: 92.0062\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 92.0149 - mean_squared_error: 92.0149\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 92.0561 - mean_squared_error: 92.0561\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 92.1268 - mean_squared_error: 92.1268\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 92.2240 - mean_squared_error: 92.2240\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 663us/step - loss: 92.3448 - mean_squared_error: 92.3448\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 92.4869 - mean_squared_error: 92.4869\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 92.6478 - mean_squared_error: 92.6478\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 92.8255 - mean_squared_error: 92.8255\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 93.0179 - mean_squared_error: 93.0179\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 93.2232 - mean_squared_error: 93.2232\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 93.4398 - mean_squared_error: 93.4398\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 93.6660 - mean_squared_error: 93.6660\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 93.9007 - mean_squared_error: 93.9007\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 94.1422 - mean_squared_error: 94.1422\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 94.3896 - mean_squared_error: 94.3896\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 94.6417 - mean_squared_error: 94.6417\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 94.8976 - mean_squared_error: 94.8976\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 95.1563 - mean_squared_error: 95.1563\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 95.4170 - mean_squared_error: 95.4170\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 95.6791 - mean_squared_error: 95.6791\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 95.9416 - mean_squared_error: 95.9416\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 96.2042 - mean_squared_error: 96.2042\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 96.4662 - mean_squared_error: 96.4662\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 96.7270 - mean_squared_error: 96.7270\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 96.9864 - mean_squared_error: 96.9864\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 97.2438 - mean_squared_error: 97.2438\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 97.4989 - mean_squared_error: 97.4989\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 97.7513 - mean_squared_error: 97.7513\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 98.0009 - mean_squared_error: 98.0009\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 98.2472 - mean_squared_error: 98.2472\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 98.4902 - mean_squared_error: 98.4902\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 98.7295 - mean_squared_error: 98.7295\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 98.9651 - mean_squared_error: 98.9651\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 99.1968 - mean_squared_error: 99.1968\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 99.4244 - mean_squared_error: 99.4244\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 99.6480 - mean_squared_error: 99.6480\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 99.8673 - mean_squared_error: 99.8673\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 100.0824 - mean_squared_error: 100.0824\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 100.2932 - mean_squared_error: 100.2932\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 100.4996 - mean_squared_error: 100.4996\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 100.7016 - mean_squared_error: 100.7016\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 100.8992 - mean_squared_error: 100.8992\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 101.0924 - mean_squared_error: 101.0924\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 101.2812 - mean_squared_error: 101.2812\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 101.4657 - mean_squared_error: 101.4657\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 101.6458 - mean_squared_error: 101.6458\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 101.8216 - mean_squared_error: 101.8216\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 101.9930 - mean_squared_error: 101.9930\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 102.1603 - mean_squared_error: 102.1603\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 102.3234 - mean_squared_error: 102.3234\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 102.4823 - mean_squared_error: 102.4823\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 102.6372 - mean_squared_error: 102.6372\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 102.7880 - mean_squared_error: 102.7880\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 102.9349 - mean_squared_error: 102.9349\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 103.0779 - mean_squared_error: 103.0779\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 103.2171 - mean_squared_error: 103.2171\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 103.3525 - mean_squared_error: 103.3525\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 103.4842 - mean_squared_error: 103.4842\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 103.6123 - mean_squared_error: 103.6123\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 103.7369 - mean_squared_error: 103.7369\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 103.8579 - mean_squared_error: 103.8579\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 103.9756 - mean_squared_error: 103.9756\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 104.0900 - mean_squared_error: 104.0900\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 104.2011 - mean_squared_error: 104.2011\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 104.3091 - mean_squared_error: 104.3091\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 104.4139 - mean_squared_error: 104.4139\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 104.5157 - mean_squared_error: 104.5157\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 104.6145 - mean_squared_error: 104.6145\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 104.7105 - mean_squared_error: 104.7105\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 104.8037 - mean_squared_error: 104.8037\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 104.8941 - mean_squared_error: 104.8941\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 104.9818 - mean_squared_error: 104.9818\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.0669 - mean_squared_error: 105.0669\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 105.1495 - mean_squared_error: 105.1495\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.2296 - mean_squared_error: 105.2296\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.3074 - mean_squared_error: 105.3074\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 105.3827 - mean_squared_error: 105.3827\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.4558 - mean_squared_error: 105.4558\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.5267 - mean_squared_error: 105.5267\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 105.5953 - mean_squared_error: 105.5953\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.6620 - mean_squared_error: 105.6620\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 105.7265 - mean_squared_error: 105.7265\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.7892 - mean_squared_error: 105.7892\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.8498 - mean_squared_error: 105.8498\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 105.9086 - mean_squared_error: 105.9086\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.9656 - mean_squared_error: 105.9656\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.0208 - mean_squared_error: 106.0208\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.0743 - mean_squared_error: 106.0743\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.1261 - mean_squared_error: 106.1261\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.1763 - mean_squared_error: 106.1763\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 106.2249 - mean_squared_error: 106.2249\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 106.2721 - mean_squared_error: 106.2721\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.3177 - mean_squared_error: 106.3177\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.3618 - mean_squared_error: 106.3618\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.4047 - mean_squared_error: 106.4047\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 106.4461 - mean_squared_error: 106.4461\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.4863 - mean_squared_error: 106.4863\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 106.5252 - mean_squared_error: 106.5252\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.5628 - mean_squared_error: 106.5628\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.5994 - mean_squared_error: 106.5994\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.6346 - mean_squared_error: 106.6346\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.6688 - mean_squared_error: 106.6688\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.7019 - mean_squared_error: 106.7019\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.7340 - mean_squared_error: 106.7340\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.7650 - mean_squared_error: 106.7650\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 106.7950 - mean_squared_error: 106.7950\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.8241 - mean_squared_error: 106.8241\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.8522 - mean_squared_error: 106.8522\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.8794 - mean_squared_error: 106.8794\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.9058 - mean_squared_error: 106.9058\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 106.9313 - mean_squared_error: 106.9313\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 106.9560 - mean_squared_error: 106.9560\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.9799 - mean_squared_error: 106.9799\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.0030 - mean_squared_error: 107.0030\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.0254 - mean_squared_error: 107.0254\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.0471 - mean_squared_error: 107.0471\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.0681 - mean_squared_error: 107.0681\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.0884 - mean_squared_error: 107.0884\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.1080 - mean_squared_error: 107.1080\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.1270 - mean_squared_error: 107.1270\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.1454 - mean_squared_error: 107.1454\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.1632 - mean_squared_error: 107.1632\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.1804 - mean_squared_error: 107.1804\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.1970 - mean_squared_error: 107.1970\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.2132 - mean_squared_error: 107.2132\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.2288 - mean_squared_error: 107.2288\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 107.2438 - mean_squared_error: 107.2438\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.2584 - mean_squared_error: 107.2584\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.2725 - mean_squared_error: 107.2725\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.2862 - mean_squared_error: 107.2862\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.2994 - mean_squared_error: 107.2994\n",
      "Epoch 144/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 107.3123 - mean_squared_error: 107.3123\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.3246 - mean_squared_error: 107.3246\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.3366 - mean_squared_error: 107.3366\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.3481 - mean_squared_error: 107.3481\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.3594 - mean_squared_error: 107.3594\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.3702 - mean_squared_error: 107.3702\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.3807 - mean_squared_error: 107.3807\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.3908 - mean_squared_error: 107.3908\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.4007 - mean_squared_error: 107.4007\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.4102 - mean_squared_error: 107.4102\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.4193 - mean_squared_error: 107.4193\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4282 - mean_squared_error: 107.4282\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.4368 - mean_squared_error: 107.4368\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4451 - mean_squared_error: 107.4451\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.4532 - mean_squared_error: 107.4532\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.4609 - mean_squared_error: 107.4609\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.4684 - mean_squared_error: 107.4684\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.4757 - mean_squared_error: 107.4757\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.4827 - mean_squared_error: 107.4827\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.4895 - mean_squared_error: 107.4895\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4962 - mean_squared_error: 107.4962\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.5026 - mean_squared_error: 107.5026\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5087 - mean_squared_error: 107.5087\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.5147 - mean_squared_error: 107.5147\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5205 - mean_squared_error: 107.5205\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.5261 - mean_squared_error: 107.5261\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5314 - mean_squared_error: 107.5314\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.5366 - mean_squared_error: 107.5366\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.5416 - mean_squared_error: 107.5416\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5465 - mean_squared_error: 107.5465\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5512 - mean_squared_error: 107.5512\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.5559 - mean_squared_error: 107.5559\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.5602 - mean_squared_error: 107.5602\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.5645 - mean_squared_error: 107.5645\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.5686 - mean_squared_error: 107.5686\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.5726 - mean_squared_error: 107.5726\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5765 - mean_squared_error: 107.5765\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.5802 - mean_squared_error: 107.5802\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5839 - mean_squared_error: 107.5839\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5873 - mean_squared_error: 107.5873\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5907 - mean_squared_error: 107.5907\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.5940 - mean_squared_error: 107.5940\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5972 - mean_squared_error: 107.5972\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6003 - mean_squared_error: 107.6003\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6032 - mean_squared_error: 107.6032\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6060 - mean_squared_error: 107.6060\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6088 - mean_squared_error: 107.6088\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6115 - mean_squared_error: 107.6115\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6141 - mean_squared_error: 107.6141\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6165 - mean_squared_error: 107.6165\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6190 - mean_squared_error: 107.6190\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6213 - mean_squared_error: 107.6213\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 107.6236 - mean_squared_error: 107.6236\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6257 - mean_squared_error: 107.6257\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6279 - mean_squared_error: 107.6279\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6300 - mean_squared_error: 107.6300\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6319 - mean_squared_error: 107.6319\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6339 - mean_squared_error: 107.6339\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6357 - mean_squared_error: 107.6357\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6375 - mean_squared_error: 107.6375\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6393 - mean_squared_error: 107.6393\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 107.6409 - mean_squared_error: 107.6409\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6425 - mean_squared_error: 107.6425\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6441 - mean_squared_error: 107.6441\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6456 - mean_squared_error: 107.6456\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6471 - mean_squared_error: 107.6471\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6485 - mean_squared_error: 107.6485\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6499 - mean_squared_error: 107.6499\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6512 - mean_squared_error: 107.6512\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6525 - mean_squared_error: 107.6525\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6538 - mean_squared_error: 107.6538\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6549 - mean_squared_error: 107.6549\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6561 - mean_squared_error: 107.6561\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6572 - mean_squared_error: 107.6572\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 107.6583 - mean_squared_error: 107.6583\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6593 - mean_squared_error: 107.6593\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6603 - mean_squared_error: 107.6603\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 107.6614 - mean_squared_error: 107.6614\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6623 - mean_squared_error: 107.6623\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6632 - mean_squared_error: 107.6632\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6641 - mean_squared_error: 107.6641\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6649 - mean_squared_error: 107.6649\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6657 - mean_squared_error: 107.6657\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 98.5995 - mean_squared_error: 98.59 - 0s 776us/step - loss: 107.6666 - mean_squared_error: 107.6666\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6674 - mean_squared_error: 107.6674\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6681 - mean_squared_error: 107.6681\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6688 - mean_squared_error: 107.6688\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6695 - mean_squared_error: 107.6695\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6702 - mean_squared_error: 107.6702\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6708 - mean_squared_error: 107.6708\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6715 - mean_squared_error: 107.6715\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 107.6721 - mean_squared_error: 107.6721\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6727 - mean_squared_error: 107.6727\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6732 - mean_squared_error: 107.6732\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6738 - mean_squared_error: 107.6738\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6743 - mean_squared_error: 107.6743\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6749 - mean_squared_error: 107.6749\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6754 - mean_squared_error: 107.6754\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6759 - mean_squared_error: 107.6759\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 107.6764 - mean_squared_error: 107.6764\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6768 - mean_squared_error: 107.6768\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6772 - mean_squared_error: 107.6772\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6777 - mean_squared_error: 107.6777\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6781 - mean_squared_error: 107.6781\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.6784 - mean_squared_error: 107.6784\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6789 - mean_squared_error: 107.6789\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6792 - mean_squared_error: 107.6792\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6796 - mean_squared_error: 107.6796\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6799 - mean_squared_error: 107.6799\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6803 - mean_squared_error: 107.6803\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6806 - mean_squared_error: 107.6806\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6809 - mean_squared_error: 107.6809\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6812 - mean_squared_error: 107.6812\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6815 - mean_squared_error: 107.6815\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6818 - mean_squared_error: 107.6818\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6821 - mean_squared_error: 107.6821\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6823 - mean_squared_error: 107.6823\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6826 - mean_squared_error: 107.6826\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6829 - mean_squared_error: 107.6829\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6831 - mean_squared_error: 107.6831\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6834 - mean_squared_error: 107.6834\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6835 - mean_squared_error: 107.6835\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6838 - mean_squared_error: 107.6838\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6840 - mean_squared_error: 107.6840\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6841 - mean_squared_error: 107.6841\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6843 - mean_squared_error: 107.6843\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6846 - mean_squared_error: 107.6846\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6847 - mean_squared_error: 107.6847\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6849 - mean_squared_error: 107.6849\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6851 - mean_squared_error: 107.6851\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6852 - mean_squared_error: 107.6852\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6854 - mean_squared_error: 107.6854\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6856 - mean_squared_error: 107.6856\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6857 - mean_squared_error: 107.6857\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6859 - mean_squared_error: 107.6859\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6860 - mean_squared_error: 107.6860\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6862 - mean_squared_error: 107.6862\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6863 - mean_squared_error: 107.6863\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6865 - mean_squared_error: 107.6865\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: 107.6865 - mean_squared_error: 107.6865\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6866 - mean_squared_error: 107.6866\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 665us/step - loss: 107.6868 - mean_squared_error: 107.6868\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6869 - mean_squared_error: 107.6869\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6870 - mean_squared_error: 107.6870\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6870 - mean_squared_error: 107.6870\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6872 - mean_squared_error: 107.6872\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6873 - mean_squared_error: 107.6873\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6874 - mean_squared_error: 107.6874\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6875 - mean_squared_error: 107.6875\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: 107.6875 - mean_squared_error: 107.6875\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6876 - mean_squared_error: 107.6876\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.6878 - mean_squared_error: 107.6878\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6878 - mean_squared_error: 107.6878\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.6879 - mean_squared_error: 107.6879\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6879 - mean_squared_error: 107.6879\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6880 - mean_squared_error: 107.6880\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6881 - mean_squared_error: 107.6881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad7023710>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선형회귀\n",
    "x=np.array([1,2,3,4,5,6,7,8,9]) #공부시간\n",
    "y=np.array([12,23,34,45,56,77,88,100,90]) #점수\n",
    "# 7.5 시간 공부? 점수?\n",
    "model=Sequential()\n",
    "model.add(Dense(1,input_dim=1, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(x,y, batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fad846cb70>,\n",
       " <matplotlib.lines.Line2D at 0x1fad846cd68>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, model.predict(x),'b',x,y,'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66.2594]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([7.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:23:33.288491 14200 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.9858 - binary_accuracy: 0.5556\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 994us/step - loss: 0.7252 - binary_accuracy: 0.6667\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6726 - binary_accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6650 - binary_accuracy: 0.4444\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 772us/step - loss: 0.6636 - binary_accuracy: 0.4444\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6621 - binary_accuracy: 0.4444\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6601 - binary_accuracy: 0.4444\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 773us/step - loss: 0.6576 - binary_accuracy: 0.4444\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 883us/step - loss: 0.6548 - binary_accuracy: 0.4444\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6519 - binary_accuracy: 0.4444\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6489 - binary_accuracy: 0.4444\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 0.6459 - binary_accuracy: 0.4444\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6429 - binary_accuracy: 0.4444\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6399 - binary_accuracy: 0.4444\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.6370 - binary_accuracy: 0.4444\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.6340 - binary_accuracy: 0.4444\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6311 - binary_accuracy: 0.5556\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6282 - binary_accuracy: 0.5556\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6254 - binary_accuracy: 0.5556\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6225 - binary_accuracy: 0.5556\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6197 - binary_accuracy: 0.5556\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.6169 - binary_accuracy: 0.5556\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6142 - binary_accuracy: 0.5556\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6114 - binary_accuracy: 0.5556\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6087 - binary_accuracy: 0.5556\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.6060 - binary_accuracy: 0.5556\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6034 - binary_accuracy: 0.5556\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.6007 - binary_accuracy: 0.5556\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5981 - binary_accuracy: 0.5556\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5955 - binary_accuracy: 0.5556\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5930 - binary_accuracy: 0.5556\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5904 - binary_accuracy: 0.5556\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.5879 - binary_accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5854 - binary_accuracy: 0.6667\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5829 - binary_accuracy: 0.6667\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5804 - binary_accuracy: 0.6667\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5780 - binary_accuracy: 0.6667\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.5756 - binary_accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5732 - binary_accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5708 - binary_accuracy: 0.6667\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5684 - binary_accuracy: 0.6667\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5661 - binary_accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.5638 - binary_accuracy: 0.6667\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5615 - binary_accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.5592 - binary_accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5570 - binary_accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5547 - binary_accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5525 - binary_accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5503 - binary_accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5481 - binary_accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.5460 - binary_accuracy: 0.6667\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5438 - binary_accuracy: 0.6667\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.5417 - binary_accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5396 - binary_accuracy: 0.6667\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5375 - binary_accuracy: 0.6667\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5354 - binary_accuracy: 0.6667\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5334 - binary_accuracy: 0.6667\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.5314 - binary_accuracy: 0.6667\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5293 - binary_accuracy: 0.7778\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 0.5273 - binary_accuracy: 0.7778\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5254 - binary_accuracy: 0.7778\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5234 - binary_accuracy: 0.7778\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5214 - binary_accuracy: 0.7778\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5195 - binary_accuracy: 0.7778\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.5176 - binary_accuracy: 0.7778\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5157 - binary_accuracy: 0.7778\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4352 - binary_accuracy: 1.000 - 0s 997us/step - loss: 0.5138 - binary_accuracy: 0.7778\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5119 - binary_accuracy: 0.7778\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5101 - binary_accuracy: 0.7778\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5082 - binary_accuracy: 0.7778\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5064 - binary_accuracy: 0.7778\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5046 - binary_accuracy: 0.7778\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5028 - binary_accuracy: 0.7778\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5010 - binary_accuracy: 0.7778\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4993 - binary_accuracy: 0.7778\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4975 - binary_accuracy: 0.7778\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 776us/step - loss: 0.4958 - binary_accuracy: 0.7778\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4941 - binary_accuracy: 0.7778\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4924 - binary_accuracy: 0.7778\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4907 - binary_accuracy: 0.7778\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4890 - binary_accuracy: 0.7778\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.4873 - binary_accuracy: 0.7778\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.4857 - binary_accuracy: 0.7778\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4840 - binary_accuracy: 0.7778\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4824 - binary_accuracy: 0.7778\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4808 - binary_accuracy: 0.7778\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4792 - binary_accuracy: 0.7778\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4776 - binary_accuracy: 0.7778\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4760 - binary_accuracy: 0.7778\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4745 - binary_accuracy: 0.7778\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4729 - binary_accuracy: 0.7778\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4714 - binary_accuracy: 0.7778\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4699 - binary_accuracy: 0.7778\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4683 - binary_accuracy: 0.7778\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4668 - binary_accuracy: 0.7778\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4653 - binary_accuracy: 0.7778\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4639 - binary_accuracy: 0.7778\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4624 - binary_accuracy: 0.7778\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4609 - binary_accuracy: 0.7778\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4595 - binary_accuracy: 0.7778\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4581 - binary_accuracy: 0.7778\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4566 - binary_accuracy: 0.7778\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4552 - binary_accuracy: 0.7778\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4538 - binary_accuracy: 0.7778\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4524 - binary_accuracy: 0.7778\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4511 - binary_accuracy: 0.7778\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4497 - binary_accuracy: 0.7778\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4483 - binary_accuracy: 0.7778\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4470 - binary_accuracy: 0.7778\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4456 - binary_accuracy: 0.7778\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4443 - binary_accuracy: 0.7778\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4430 - binary_accuracy: 0.8889\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4417 - binary_accuracy: 0.8889\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.4404 - binary_accuracy: 0.8889\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4391 - binary_accuracy: 0.8889\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4378 - binary_accuracy: 0.8889\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4366 - binary_accuracy: 0.8889\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4353 - binary_accuracy: 0.8889\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4340 - binary_accuracy: 0.8889\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4328 - binary_accuracy: 0.8889\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4316 - binary_accuracy: 0.8889\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2788 - binary_accuracy: 1.000 - 0s 886us/step - loss: 0.4303 - binary_accuracy: 0.8889\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4291 - binary_accuracy: 0.8889\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4279 - binary_accuracy: 0.8889\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4267 - binary_accuracy: 0.8889\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4255 - binary_accuracy: 0.8889\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4244 - binary_accuracy: 0.8889\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4232 - binary_accuracy: 0.8889\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4220 - binary_accuracy: 0.8889\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 0.4209 - binary_accuracy: 0.8889\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4197 - binary_accuracy: 0.8889\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4186 - binary_accuracy: 0.8889\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4174 - binary_accuracy: 0.8889\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.4163 - binary_accuracy: 0.8889\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4152 - binary_accuracy: 0.8889\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 0.4141 - binary_accuracy: 0.8889\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4130 - binary_accuracy: 0.8889\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4119 - binary_accuracy: 0.8889\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4108 - binary_accuracy: 0.8889\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4097 - binary_accuracy: 0.8889\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4087 - binary_accuracy: 0.8889\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4076 - binary_accuracy: 0.8889\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.4065 - binary_accuracy: 0.8889\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4055 - binary_accuracy: 0.8889\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4045 - binary_accuracy: 0.8889\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4034 - binary_accuracy: 0.8889\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.4024 - binary_accuracy: 0.8889\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4014 - binary_accuracy: 0.8889\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4004 - binary_accuracy: 0.8889\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3994 - binary_accuracy: 0.8889\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3984 - binary_accuracy: 0.8889\n",
      "Epoch 152/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 887us/step - loss: 0.3974 - binary_accuracy: 0.8889\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3964 - binary_accuracy: 0.8889\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3954 - binary_accuracy: 0.8889\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3944 - binary_accuracy: 0.8889\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.3935 - binary_accuracy: 0.8889\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3925 - binary_accuracy: 0.8889\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3915 - binary_accuracy: 0.8889\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3906 - binary_accuracy: 0.8889\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3897 - binary_accuracy: 0.8889\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3887 - binary_accuracy: 0.8889\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.3878 - binary_accuracy: 0.8889\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.3869 - binary_accuracy: 0.8889\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3859 - binary_accuracy: 0.8889\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3850 - binary_accuracy: 0.8889\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3841 - binary_accuracy: 0.8889\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3832 - binary_accuracy: 0.8889\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3823 - binary_accuracy: 0.8889\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3814 - binary_accuracy: 0.8889\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3806 - binary_accuracy: 0.8889\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3797 - binary_accuracy: 0.8889\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3788 - binary_accuracy: 0.8889\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3779 - binary_accuracy: 0.8889\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3771 - binary_accuracy: 0.8889\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3762 - binary_accuracy: 0.8889\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3754 - binary_accuracy: 0.8889\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3745 - binary_accuracy: 0.8889\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3737 - binary_accuracy: 0.8889\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3729 - binary_accuracy: 0.8889\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3720 - binary_accuracy: 0.8889\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3712 - binary_accuracy: 0.8889\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3704 - binary_accuracy: 0.8889\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 0.3696 - binary_accuracy: 0.8889\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3688 - binary_accuracy: 0.8889\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3680 - binary_accuracy: 0.8889\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3672 - binary_accuracy: 0.8889\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3664 - binary_accuracy: 0.8889\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3656 - binary_accuracy: 0.8889\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3648 - binary_accuracy: 0.8889\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 0.3640 - binary_accuracy: 0.8889\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3632 - binary_accuracy: 0.8889\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3625 - binary_accuracy: 0.8889\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3617 - binary_accuracy: 0.8889\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3609 - binary_accuracy: 0.8889\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.3602 - binary_accuracy: 0.8889\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3594 - binary_accuracy: 0.8889\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3587 - binary_accuracy: 0.8889\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3579 - binary_accuracy: 0.8889\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3572 - binary_accuracy: 0.8889\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3564 - binary_accuracy: 0.8889\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3557 - binary_accuracy: 0.8889\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3550 - binary_accuracy: 0.8889\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3543 - binary_accuracy: 0.8889\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 0.3535 - binary_accuracy: 0.8889\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 0.3528 - binary_accuracy: 0.8889\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3521 - binary_accuracy: 0.8889\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3514 - binary_accuracy: 0.8889\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3507 - binary_accuracy: 0.8889\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.3500 - binary_accuracy: 0.8889\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3493 - binary_accuracy: 0.8889\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3486 - binary_accuracy: 0.8889\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3479 - binary_accuracy: 0.8889\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 0.3473 - binary_accuracy: 0.8889\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.3466 - binary_accuracy: 0.8889\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3459 - binary_accuracy: 0.8889\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3452 - binary_accuracy: 0.8889\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.3446 - binary_accuracy: 0.8889\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3439 - binary_accuracy: 0.8889\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.3432 - binary_accuracy: 0.8889\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3426 - binary_accuracy: 0.8889\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3419 - binary_accuracy: 0.8889\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3413 - binary_accuracy: 0.8889\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3406 - binary_accuracy: 0.8889\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3400 - binary_accuracy: 0.8889\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3393 - binary_accuracy: 0.8889\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3387 - binary_accuracy: 0.8889\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3381 - binary_accuracy: 0.8889\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 887us/step - loss: 0.3374 - binary_accuracy: 0.8889\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3368 - binary_accuracy: 0.8889\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3362 - binary_accuracy: 0.8889\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3356 - binary_accuracy: 0.8889\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3350 - binary_accuracy: 0.8889\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3343 - binary_accuracy: 0.8889\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3337 - binary_accuracy: 0.8889\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.3331 - binary_accuracy: 0.8889\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3325 - binary_accuracy: 0.8889\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3319 - binary_accuracy: 0.8889\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3313 - binary_accuracy: 0.8889\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3307 - binary_accuracy: 0.8889\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3301 - binary_accuracy: 0.8889\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3296 - binary_accuracy: 0.8889\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3290 - binary_accuracy: 0.8889\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3284 - binary_accuracy: 0.8889\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3278 - binary_accuracy: 0.8889\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3272 - binary_accuracy: 0.8889\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3267 - binary_accuracy: 0.8889\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3261 - binary_accuracy: 0.8889\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3255 - binary_accuracy: 0.8889\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.3250 - binary_accuracy: 0.8889\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3244 - binary_accuracy: 0.8889\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3238 - binary_accuracy: 0.8889\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3233 - binary_accuracy: 0.8889\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3227 - binary_accuracy: 0.8889\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3222 - binary_accuracy: 0.8889\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3216 - binary_accuracy: 0.8889\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3211 - binary_accuracy: 0.8889\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3206 - binary_accuracy: 0.8889\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3200 - binary_accuracy: 0.8889\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3195 - binary_accuracy: 0.8889\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1166 - binary_accuracy: 1.000 - 0s 997us/step - loss: 0.3189 - binary_accuracy: 0.8889\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3184 - binary_accuracy: 0.8889\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3179 - binary_accuracy: 0.8889\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.3174 - binary_accuracy: 0.8889\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3168 - binary_accuracy: 0.8889\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3163 - binary_accuracy: 0.8889\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3158 - binary_accuracy: 0.8889\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3153 - binary_accuracy: 0.8889\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3148 - binary_accuracy: 0.8889\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3143 - binary_accuracy: 0.8889\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3138 - binary_accuracy: 0.8889\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3132 - binary_accuracy: 0.8889\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3127 - binary_accuracy: 0.8889\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3122 - binary_accuracy: 0.8889\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3117 - binary_accuracy: 0.8889\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3112 - binary_accuracy: 0.8889\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3108 - binary_accuracy: 0.8889\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3103 - binary_accuracy: 0.8889\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3098 - binary_accuracy: 0.8889\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3093 - binary_accuracy: 0.8889\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3088 - binary_accuracy: 0.8889\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3083 - binary_accuracy: 0.8889\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3078 - binary_accuracy: 0.8889\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 0.3074 - binary_accuracy: 0.8889\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3069 - binary_accuracy: 0.8889\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3064 - binary_accuracy: 0.8889\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3059 - binary_accuracy: 0.8889\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3055 - binary_accuracy: 0.8889\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3050 - binary_accuracy: 0.8889\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3045 - binary_accuracy: 0.8889\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3041 - binary_accuracy: 0.8889\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3036 - binary_accuracy: 0.8889\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3032 - binary_accuracy: 0.8889\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.3027 - binary_accuracy: 0.8889\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.3022 - binary_accuracy: 0.8889\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.3018 - binary_accuracy: 0.8889\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.3013 - binary_accuracy: 0.8889\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.3009 - binary_accuracy: 0.8889\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.3004 - binary_accuracy: 0.8889\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3000 - binary_accuracy: 0.8889\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.2996 - binary_accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad7fa1748>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀\n",
    "x=np.array([1,2,3,4,5,6,7,8,9])#공부시간\n",
    "y=np.array([0,0,0,0,0,1,1,1,1])#합격여부\n",
    "#7.5시간 공부? \n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fad875d2e8>,\n",
       " <matplotlib.lines.Line2D at 0x1fad875d438>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x),'b',x,y,'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9984981 ],\n",
       "       [0.99957293]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([15, 17])\n",
    "model.predict([0.5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 0s 61ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 996us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 994us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 73/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 996us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 995us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 995us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - ETA: 0s - loss: -1450.7570 - binary_accuracy: 0.0000e+0 - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 216/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 993us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - ETA: 0s - loss: -1450.7570 - binary_accuracy: 0.0000e+0 - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - ETA: 0s - loss: -1450.7570 - binary_accuracy: 0.0000e+0 - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 286/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 997us/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -1312.5896 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad9c6b358>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hx=w1x1+w2x2+w3x3+b\n",
    "x=np.array([[100,90,80],[55,45,36],[77,88,90]])#중간,기말,최종\n",
    "y=np.array([92, 70, 88])\n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=3, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.00001)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.27   ],\n",
       "       [ 52.01368],\n",
       "       [ 88.93912]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x) #[92, 70, 88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.6359 - binary_accuracy: 0.7500\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6300 - binary_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.6242 - binary_accuracy: 0.7500\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6185 - binary_accuracy: 0.7500\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6131 - binary_accuracy: 0.7500\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6077 - binary_accuracy: 0.7500\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6026 - binary_accuracy: 0.7500\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5976 - binary_accuracy: 0.7500\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5927 - binary_accuracy: 0.7500\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5879 - binary_accuracy: 0.7500\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5833 - binary_accuracy: 0.7500\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5789 - binary_accuracy: 0.7500\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5745 - binary_accuracy: 0.7500\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5703 - binary_accuracy: 0.7500\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5661 - binary_accuracy: 0.7500\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5621 - binary_accuracy: 0.7500\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5582 - binary_accuracy: 0.7500\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5544 - binary_accuracy: 0.7500\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5507 - binary_accuracy: 0.7500\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5471 - binary_accuracy: 0.7500\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5436 - binary_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.5402 - binary_accuracy: 0.7500\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5368 - binary_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5336 - binary_accuracy: 0.7500\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5304 - binary_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5273 - binary_accuracy: 0.7500\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5243 - binary_accuracy: 0.7500\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5214 - binary_accuracy: 0.7500\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5185 - binary_accuracy: 0.7500\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5157 - binary_accuracy: 0.7500\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5130 - binary_accuracy: 0.7500\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5103 - binary_accuracy: 0.7500\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5077 - binary_accuracy: 0.7500\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5052 - binary_accuracy: 0.7500\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5027 - binary_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5003 - binary_accuracy: 0.7500\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4979 - binary_accuracy: 0.7500\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 994us/step - loss: 0.4956 - binary_accuracy: 0.7500\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4933 - binary_accuracy: 0.7500\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4911 - binary_accuracy: 0.7500\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4889 - binary_accuracy: 0.7500\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4868 - binary_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4847 - binary_accuracy: 0.7500\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4827 - binary_accuracy: 0.7500\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4807 - binary_accuracy: 0.7500\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4787 - binary_accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4768 - binary_accuracy: 0.7500\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4750 - binary_accuracy: 0.7500\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4731 - binary_accuracy: 0.7500\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 995us/step - loss: 0.4713 - binary_accuracy: 0.7500\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4696 - binary_accuracy: 0.7500\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4679 - binary_accuracy: 0.7500\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4662 - binary_accuracy: 0.7500\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4645 - binary_accuracy: 0.7500\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4629 - binary_accuracy: 0.7500\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4613 - binary_accuracy: 0.7500\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4597 - binary_accuracy: 0.7500\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4582 - binary_accuracy: 0.7500\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4567 - binary_accuracy: 0.7500\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4552 - binary_accuracy: 0.7500\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4537 - binary_accuracy: 0.7500\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4523 - binary_accuracy: 0.7500\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4509 - binary_accuracy: 0.7500\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4495 - binary_accuracy: 0.7500\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4481 - binary_accuracy: 0.7500\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4468 - binary_accuracy: 0.7500\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4455 - binary_accuracy: 0.7500\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4442 - binary_accuracy: 0.7500\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4429 - binary_accuracy: 0.7500\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4416 - binary_accuracy: 0.7500\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4404 - binary_accuracy: 0.7500\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4392 - binary_accuracy: 0.7500\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4380 - binary_accuracy: 0.7500\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.4368 - binary_accuracy: 0.7500\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4357 - binary_accuracy: 0.7500\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4345 - binary_accuracy: 0.7500\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4334 - binary_accuracy: 0.7500\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4323 - binary_accuracy: 0.7500\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4312 - binary_accuracy: 0.7500\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 995us/step - loss: 0.4301 - binary_accuracy: 0.7500\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4291 - binary_accuracy: 0.7500\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4280 - binary_accuracy: 0.7500\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4270 - binary_accuracy: 0.7500\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4260 - binary_accuracy: 0.7500\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4250 - binary_accuracy: 0.7500\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4240 - binary_accuracy: 0.7500\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4230 - binary_accuracy: 0.7500\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4220 - binary_accuracy: 0.7500\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4211 - binary_accuracy: 0.7500\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.4201 - binary_accuracy: 0.7500\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4192 - binary_accuracy: 0.7500\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4183 - binary_accuracy: 0.7500\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4174 - binary_accuracy: 0.7500\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4165 - binary_accuracy: 0.7500\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4156 - binary_accuracy: 0.7500\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4147 - binary_accuracy: 0.7500\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4139 - binary_accuracy: 0.7500\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4130 - binary_accuracy: 0.7500\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4122 - binary_accuracy: 0.7500\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4113 - binary_accuracy: 0.7500\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4105 - binary_accuracy: 0.7500\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4097 - binary_accuracy: 0.7500\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4089 - binary_accuracy: 0.7500\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4081 - binary_accuracy: 0.7500\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4073 - binary_accuracy: 0.7500\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4065 - binary_accuracy: 0.7500\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4057 - binary_accuracy: 0.7500\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8931 - binary_accuracy: 0.0000e+0 - 0s 1ms/step - loss: 0.4050 - binary_accuracy: 0.7500\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4042 - binary_accuracy: 0.7500\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4035 - binary_accuracy: 0.7500\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4027 - binary_accuracy: 0.7500\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4020 - binary_accuracy: 0.7500\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4013 - binary_accuracy: 0.7500\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4005 - binary_accuracy: 0.7500\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3998 - binary_accuracy: 0.7500\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3991 - binary_accuracy: 0.7500\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3984 - binary_accuracy: 0.7500\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3977 - binary_accuracy: 0.7500\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3970 - binary_accuracy: 0.7500\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3963 - binary_accuracy: 0.7500\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3957 - binary_accuracy: 0.7500\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3950 - binary_accuracy: 0.7500\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3943 - binary_accuracy: 0.7500\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3937 - binary_accuracy: 0.7500\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3930 - binary_accuracy: 0.7500\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8960 - binary_accuracy: 0.0000e+0 - 0s 998us/step - loss: 0.3924 - binary_accuracy: 0.7500\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3917 - binary_accuracy: 0.7500\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3911 - binary_accuracy: 0.7500\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3904 - binary_accuracy: 0.7500\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3898 - binary_accuracy: 0.7500\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3892 - binary_accuracy: 0.7500\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.3886 - binary_accuracy: 0.7500\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3879 - binary_accuracy: 0.7500\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3873 - binary_accuracy: 0.7500\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3867 - binary_accuracy: 0.7500\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3861 - binary_accuracy: 0.7500\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3855 - binary_accuracy: 0.7500\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3849 - binary_accuracy: 0.7500\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3843 - binary_accuracy: 0.7500\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3838 - binary_accuracy: 0.7500\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3832 - binary_accuracy: 0.7500\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3826 - binary_accuracy: 0.7500\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3820 - binary_accuracy: 0.7500\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3814 - binary_accuracy: 0.7500\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3809 - binary_accuracy: 0.7500\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3803 - binary_accuracy: 0.7500\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3798 - binary_accuracy: 0.7500\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3792 - binary_accuracy: 0.7500\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3786 - binary_accuracy: 0.7500\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3781 - binary_accuracy: 0.7500\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3776 - binary_accuracy: 0.7500\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3770 - binary_accuracy: 0.7500\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3765 - binary_accuracy: 0.7500\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3759 - binary_accuracy: 0.7500\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3754 - binary_accuracy: 0.7500\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3749 - binary_accuracy: 0.7500\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3743 - binary_accuracy: 0.7500\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 994us/step - loss: 0.3738 - binary_accuracy: 0.7500\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3733 - binary_accuracy: 0.7500\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3728 - binary_accuracy: 0.7500\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3723 - binary_accuracy: 0.7500\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3718 - binary_accuracy: 0.7500\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3712 - binary_accuracy: 0.7500\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3707 - binary_accuracy: 0.7500\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3702 - binary_accuracy: 0.7500\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3697 - binary_accuracy: 0.7500\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3692 - binary_accuracy: 0.7500\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3687 - binary_accuracy: 0.7500\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3682 - binary_accuracy: 0.7500\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3677 - binary_accuracy: 0.7500\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3673 - binary_accuracy: 0.7500\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3668 - binary_accuracy: 0.7500\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3663 - binary_accuracy: 0.7500\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3658 - binary_accuracy: 0.7500\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3653 - binary_accuracy: 0.7500\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3648 - binary_accuracy: 0.7500\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.3644 - binary_accuracy: 0.7500\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3639 - binary_accuracy: 0.7500\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3634 - binary_accuracy: 0.7500\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3630 - binary_accuracy: 0.7500\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3625 - binary_accuracy: 0.7500\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3620 - binary_accuracy: 0.7500\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3616 - binary_accuracy: 0.7500\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3611 - binary_accuracy: 0.7500\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3606 - binary_accuracy: 0.7500\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3602 - binary_accuracy: 0.7500\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3597 - binary_accuracy: 0.7500\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8799 - binary_accuracy: 0.0000e+0 - 0s 998us/step - loss: 0.3593 - binary_accuracy: 0.7500\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3588 - binary_accuracy: 0.7500\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3584 - binary_accuracy: 0.7500\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3579 - binary_accuracy: 0.7500\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3575 - binary_accuracy: 0.7500\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3570 - binary_accuracy: 0.7500\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3566 - binary_accuracy: 0.7500\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3561 - binary_accuracy: 0.7500\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.3557 - binary_accuracy: 0.7500\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3553 - binary_accuracy: 0.7500\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3548 - binary_accuracy: 0.7500\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3544 - binary_accuracy: 0.7500\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3540 - binary_accuracy: 0.7500\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3535 - binary_accuracy: 0.7500\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3531 - binary_accuracy: 0.7500\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3527 - binary_accuracy: 0.7500\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3522 - binary_accuracy: 0.7500\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3518 - binary_accuracy: 0.7500\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3514 - binary_accuracy: 0.7500\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3510 - binary_accuracy: 0.7500\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3505 - binary_accuracy: 0.7500\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3501 - binary_accuracy: 0.7500\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3497 - binary_accuracy: 0.7500\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3493 - binary_accuracy: 0.7500\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3489 - binary_accuracy: 0.7500\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3485 - binary_accuracy: 0.7500\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3481 - binary_accuracy: 0.7500\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3476 - binary_accuracy: 0.7500\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3472 - binary_accuracy: 0.7500\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3468 - binary_accuracy: 0.7500\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3464 - binary_accuracy: 0.7500\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3460 - binary_accuracy: 0.7500\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3456 - binary_accuracy: 0.7500\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 995us/step - loss: 0.3452 - binary_accuracy: 0.7500\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3448 - binary_accuracy: 0.7500\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3444 - binary_accuracy: 0.7500\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3440 - binary_accuracy: 0.7500\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3436 - binary_accuracy: 0.7500\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3432 - binary_accuracy: 0.7500\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3428 - binary_accuracy: 0.7500\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3424 - binary_accuracy: 0.7500\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3420 - binary_accuracy: 0.7500\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 997us/step - loss: 0.3416 - binary_accuracy: 0.7500\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3412 - binary_accuracy: 0.7500\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3408 - binary_accuracy: 0.7500\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3405 - binary_accuracy: 0.7500\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3401 - binary_accuracy: 0.7500\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3397 - binary_accuracy: 0.7500\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.3393 - binary_accuracy: 0.7500\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3389 - binary_accuracy: 0.7500\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3385 - binary_accuracy: 0.7500\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3381 - binary_accuracy: 0.7500\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3378 - binary_accuracy: 0.7500\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3374 - binary_accuracy: 0.7500\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3370 - binary_accuracy: 0.7500\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3366 - binary_accuracy: 0.7500\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3362 - binary_accuracy: 0.7500\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3359 - binary_accuracy: 0.7500\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3355 - binary_accuracy: 0.7500\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3351 - binary_accuracy: 0.7500\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3347 - binary_accuracy: 0.7500\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3344 - binary_accuracy: 0.7500\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3340 - binary_accuracy: 0.7500\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3336 - binary_accuracy: 0.7500\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - binary_accuracy: 0.7500\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.3329 - binary_accuracy: 0.7500\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3325 - binary_accuracy: 0.7500\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3322 - binary_accuracy: 0.7500\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3318 - binary_accuracy: 0.7500\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3314 - binary_accuracy: 0.7500\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3311 - binary_accuracy: 0.7500\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3307 - binary_accuracy: 0.7500\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3303 - binary_accuracy: 0.7500\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3300 - binary_accuracy: 0.7500\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3296 - binary_accuracy: 0.7500\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3293 - binary_accuracy: 0.7500\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3289 - binary_accuracy: 0.7500\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3285 - binary_accuracy: 0.7500\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3282 - binary_accuracy: 0.7500\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3278 - binary_accuracy: 0.7500\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3275 - binary_accuracy: 0.7500\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3271 - binary_accuracy: 0.7500\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3268 - binary_accuracy: 0.7500\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3264 - binary_accuracy: 0.7500\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3261 - binary_accuracy: 0.7500\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3257 - binary_accuracy: 0.7500\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3254 - binary_accuracy: 0.7500\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3250 - binary_accuracy: 0.7500\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3247 - binary_accuracy: 0.7500\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3243 - binary_accuracy: 0.7500\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3240 - binary_accuracy: 0.7500\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3236 - binary_accuracy: 0.7500\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3233 - binary_accuracy: 0.7500\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3229 - binary_accuracy: 0.7500\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3226 - binary_accuracy: 0.7500\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3223 - binary_accuracy: 0.7500\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3219 - binary_accuracy: 0.7500\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3216 - binary_accuracy: 0.7500\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3212 - binary_accuracy: 0.7500\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3209 - binary_accuracy: 0.7500\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3206 - binary_accuracy: 0.7500\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3202 - binary_accuracy: 0.7500\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3199 - binary_accuracy: 0.7500\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3195 - binary_accuracy: 0.7500\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3192 - binary_accuracy: 0.7500\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3189 - binary_accuracy: 0.7500\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3185 - binary_accuracy: 0.7500\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3182 - binary_accuracy: 0.7500\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3179 - binary_accuracy: 0.7500\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3175 - binary_accuracy: 0.7500\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3172 - binary_accuracy: 0.7500\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3169 - binary_accuracy: 0.7500\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3165 - binary_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fad9abb0f0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#다중 로지스틱 회귀\n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([0,1,1,1])\n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=2, activation='sigmoid'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5533667],\n",
       "       [0.8315733],\n",
       "       [0.8069323],\n",
       "       [0.9433601]], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
