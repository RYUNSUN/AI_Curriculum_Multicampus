{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더미 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러개의 범주형 자료 => 가변수 설정\n",
    "df=pd.DataFrame({'m_id':[1,2,3,4,5],\n",
    "            'm_gen':['rock','rock','pop','disco','pop']},\n",
    "            columns=['m_id','m_gen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_id</th>\n",
       "      <th>m_gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>disco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_id  m_gen\n",
       "0     1   rock\n",
       "1     2   rock\n",
       "2     3    pop\n",
       "3     4  disco\n",
       "4     5    pop"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5\n",
       "0  1  0  0  0  0\n",
       "1  0  1  0  0  0\n",
       "2  0  0  1  0  0\n",
       "3  0  0  0  1  0\n",
       "4  0  0  0  0  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm=pd.get_dummies(df['m_id'])\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disco</th>\n",
       "      <th>pop</th>\n",
       "      <th>rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disco  pop  rock\n",
       "0      0    0     1\n",
       "1      0    0     1\n",
       "2      0    1     0\n",
       "3      1    0     0\n",
       "4      0    1     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm=pd.get_dummies(df['m_gen'])\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_id</th>\n",
       "      <th>m_gen</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>genre_3</th>\n",
       "      <th>genre_4</th>\n",
       "      <th>genre_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rock</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rock</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pop</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>disco</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pop</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_id  m_gen  genre_1  genre_2  genre_3  genre_4  genre_5\n",
       "0     1   rock        1        0        0        0        0\n",
       "1     2   rock        0        1        0        0        0\n",
       "2     3    pop        0        0        1        0        0\n",
       "3     4  disco        0        0        0        1        0\n",
       "4     5    pop        0        0        0        0        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm=df.join(mm.add_prefix('genre_'))\n",
    "mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5만개 train 이미지(입력, 레이블) => 모델\n",
    "# 1만개 test 이미지 => 모델 => 출력결과 정확도?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes=10 #분류결과의 종류 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 10:49:45.967214 14404 deprecation.py:323] From <ipython-input-22-5f585224a1ed>:8: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,28*28])\n",
    "y = tf.placeholder(tf.float32, [None,nb_classes])\n",
    "w = tf.Variable(tf.random_normal([28*28,nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "hf = tf.nn.softmax(tf.matmul(x,w)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "is_correct = tf.equal(tf.arg_max(hf,1), tf.arg_max(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "#에폭(전체 데이터를 1번 트레이닝 -> 1에폭)\n",
    "training_epochs=15\n",
    "batch_size=100 # 한번에 이미지 100개씩 읽어서 모델을 만들겠다는 의미 \n",
    "# 5만개 이미지를 15번 트레이닝하겠다는 의미 \n",
    "# 5만개 이미지는 10개(0~9개 이미지)로 분류되므로 이미지 1개 5000개씩 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 cost: 2.530654409\n",
      "Epoch:    2 cost: 1.070437187\n",
      "Epoch:    3 cost: 0.856291815\n",
      "Epoch:    4 cost: 0.751059485\n",
      "Epoch:    5 cost: 0.684664240\n",
      "Epoch:    6 cost: 0.637401114\n",
      "Epoch:    7 cost: 0.601829903\n",
      "Epoch:    8 cost: 0.573228710\n",
      "Epoch:    9 cost: 0.549600203\n",
      "Epoch:   10 cost: 0.529506460\n",
      "Epoch:   11 cost: 0.512433297\n",
      "Epoch:   12 cost: 0.497759866\n",
      "Epoch:   13 cost: 0.484976103\n",
      "Epoch:   14 cost: 0.473409090\n",
      "Epoch:   15 cost: 0.462843170\n",
      "learning finished\n",
      "accuarcy: 0.8915\n",
      "Label: [5]\n",
      "Prediction: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 원래 session객체를 쓰면 닫아줘야하는데 with 구문으로 쓰면 닫을 필요 없음\n",
    "# with 구문을 벗어나면 session 객체가 해제됨\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs): # 5만개 이미지 * 15번 트레이닝\n",
    "        avg_cost=0\n",
    "        total_batch=int(mnist.train.num_examples / batch_size) # 5만/100\n",
    "        for i in range(total_batch): # 500번(1번에 100개씩 이미지를 읽겠다) => for문이 한번 다 돌면 에폭 1\n",
    "            batch_xs, batch_ys=mnist.train.next_batch(batch_size) #이미지 100개씩 읽어오기 \n",
    "            # batch_xs=[100,784], batch_ys=[100,10]\n",
    "            cv,_=sess.run([cost,train], feed_dict={x:batch_xs,y:batch_ys}) # cv는 100개의 데이터에 대한 cost\n",
    "            avg_cost+=cv/total_batch #100개 데이터 cost/500\n",
    "        print(\"Epoch:\",\"%4d\" % (epoch+1),\n",
    "             'cost:','{:.9f}'.format(avg_cost))\n",
    "    print(\"learning finished\")\n",
    "    print(\"accuarcy:\" ,sess.run(accuracy, feed_dict={x:mnist.test.images,y:mnist.test.labels}))\n",
    "# 1,3,7,10,14 => 35/5=7\n",
    "# 0.2, 0.6, 1.4,2,2.8 => 합은 7\n",
    "    r=random.randint(0, mnist.test.num_examples-1) \n",
    "    # 0부터 텍스트 이미지 데이터 개수-1 사이의 값 중 랜덤으로 정수 난수 생성 => 테스트를 하고자하는 이미지 \n",
    "    print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n",
    "    print(\"Prediction:\", sess.run(tf.argmax(hf,1), feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow XOR 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=[[0,0],[0,1],[1,0],[1,1]]\n",
    "ydata=[[0],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "x=tf.placeholder(tf.float32,[None,2])\n",
    "y=tf.placeholder(tf.float32,[None,1])\n",
    "w=tf.Variable(tf.random_normal([2,1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.sigmoid(tf.matmul(x,w)+b) # hf값을 0 또는 1로 출력되도록 sigmoid 취하기 \n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted=tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0719781 [[-0.4729615]\n",
      " [-0.6273164]]\n",
      "100 0.6938585 [[0.10852448]\n",
      " [0.02083156]]\n",
      "200 0.69336855 [[0.07610168]\n",
      " [0.02924813]]\n",
      "300 0.69324225 [[0.04822697]\n",
      " [0.02319653]]\n",
      "400 0.6931888 [[0.03079358]\n",
      " [0.01742185]]\n",
      "500 0.6931657 [[0.01984385]\n",
      " [0.01270047]]\n",
      "600 0.6931554 [[0.01289124]\n",
      " [0.00907516]]\n",
      "700 0.69315094 [[0.0084326 ]\n",
      " [0.00639399]]\n",
      "800 0.69314885 [[0.00554824]\n",
      " [0.00445918]]\n",
      "900 0.6931479 [[0.00366821]\n",
      " [0.00308644]]\n",
      "1000 0.69314754 [[0.00243499]\n",
      " [0.00212416]]\n",
      "1100 0.69314736 [[0.00162166]\n",
      " [0.00145561]]\n",
      "1200 0.6931472 [[0.00108285]\n",
      " [0.00099415]]\n",
      "1300 0.69314724 [[0.00072464]\n",
      " [0.00067726]]\n",
      "1400 0.6931472 [[0.00048582]\n",
      " [0.00046052]]\n",
      "1500 0.69314724 [[0.00032612]\n",
      " [0.0003126 ]]\n",
      "1600 0.6931472 [[0.00021916]\n",
      " [0.00021194]]\n",
      "1700 0.6931472 [[0.0001474 ]\n",
      " [0.00014354]]\n",
      "1800 0.6931472 [[9.9208381e-05]\n",
      " [9.7151365e-05]]\n",
      "1900 0.6931472 [[6.6807304e-05]\n",
      " [6.5709915e-05]]\n",
      "2000 0.6931472 [[4.5008393e-05]\n",
      " [4.4423603e-05]]\n",
      "2100 0.6931472 [[3.0335219e-05]\n",
      " [3.0018649e-05]]\n",
      "2200 0.6931472 [[2.0445315e-05]\n",
      " [2.0277761e-05]]\n",
      "2300 0.6931472 [[1.3783008e-05]\n",
      " [1.3695915e-05]]\n",
      "2400 0.6931472 [[9.297762e-06]\n",
      " [9.249409e-06]]\n",
      "2500 0.6931472 [[6.263888e-06]\n",
      " [6.239375e-06]]\n",
      "2600 0.6931472 [[4.2298757e-06]\n",
      " [4.2202651e-06]]\n",
      "2700 0.6931472 [[2.8232055e-06]\n",
      " [2.8225359e-06]]\n",
      "2800 0.6931472 [[1.9350941e-06]\n",
      " [1.9344245e-06]]\n",
      "2900 0.6931472 [[1.2854020e-06]\n",
      " [1.2862225e-06]]\n",
      "3000 0.6931472 [[8.6965667e-07]\n",
      " [8.7047715e-07]]\n",
      "3100 0.6931471 [[5.612020e-07]\n",
      " [5.620225e-07]]\n",
      "3200 0.6931472 [[3.883485e-07]\n",
      " [3.891690e-07]]\n",
      "3300 0.6931471 [[2.4380668e-07]\n",
      " [2.4462719e-07]]\n",
      "3400 0.6931472 [[1.6781047e-07]\n",
      " [1.6863098e-07]]\n",
      "3500 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "3600 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "3700 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "3800 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "3900 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4000 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4100 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4200 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4300 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4400 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4500 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4600 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4700 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4800 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "4900 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5000 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5100 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5200 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5300 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5400 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5500 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5600 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5700 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5800 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "5900 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6000 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6100 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6200 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6300 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6400 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6500 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6600 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6700 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6800 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "6900 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7000 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7100 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7200 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7300 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7400 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7500 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7600 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7700 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7800 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "7900 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8000 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8100 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8200 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8300 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8400 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8500 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8600 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8700 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8800 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "8900 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9000 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9100 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9200 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9300 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9400 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9500 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9600 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9700 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9800 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "9900 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "10000 0.6931472 [[1.3204755e-07]\n",
      " [1.3286805e-07]]\n",
      "hf: [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] pre: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] acc: 0.5\n",
      "bias: [-1.7763747e-07]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata,y:ydata})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={x:xdata,y:ydata}),\n",
    "                 sess.run(w))\n",
    "    hv,pv,av=sess.run([hf, predicted, accuracy],feed_dict={x:xdata,y:ydata})\n",
    "    print(\"hf:\",hv,\"pre:\",pv,\"acc:\",av)\n",
    "    print(\"bias:\",sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=[[0,0],[0,1],[1,0],[1,1]]\n",
    "ydata=[[0],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,2])\n",
    "y=tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,2]))\n",
    "b1=tf.Variable(tf.random_normal([2]))\n",
    "L1=tf.sigmoid(tf.matmul(x,w1)+b1) # [None,2]\n",
    "\n",
    "w2=tf.Variable(tf.random_normal([2,1]))\n",
    "b2=tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.sigmoid(tf.matmul(L1,w2)+b2)\n",
    "\n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted=tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "cost: 0.8091888 \n",
      "w1: [[-0.7444174   0.09767172]\n",
      " [ 0.3188605  -0.989869  ]] \n",
      "w2: [[0.02539168]\n",
      " [0.06557688]]\n",
      "100 \n",
      "cost: 0.69318676 \n",
      "w1: [[-0.72878975  0.12739241]\n",
      " [ 0.33056808 -0.98616   ]] \n",
      "w2: [[0.38630638]\n",
      " [0.22766113]]\n",
      "200 \n",
      "cost: 0.6928748 \n",
      "w1: [[-0.7298085  0.1568503]\n",
      " [ 0.3238133 -0.9891866]] \n",
      "w2: [[0.39248028]\n",
      " [0.2500529 ]]\n",
      "300 \n",
      "cost: 0.6927068 \n",
      "w1: [[-0.7323847   0.18818425]\n",
      " [ 0.3169577  -0.9936031 ]] \n",
      "w2: [[0.38605845]\n",
      " [0.27007255]]\n",
      "400 \n",
      "cost: 0.6925104 \n",
      "w1: [[-0.73538375  0.22201319]\n",
      " [ 0.3112231  -0.99929404]] \n",
      "w2: [[0.37973982]\n",
      " [0.2930884 ]]\n",
      "500 \n",
      "cost: 0.6922768 \n",
      "w1: [[-0.7387797   0.25871128]\n",
      " [ 0.30659986 -1.0065426 ]] \n",
      "w2: [[0.37396574]\n",
      " [0.3195396 ]]\n",
      "600 \n",
      "cost: 0.6919947 \n",
      "w1: [[-0.74259794  0.29865843]\n",
      " [ 0.30304968 -1.0157162 ]] \n",
      "w2: [[0.36877635]\n",
      " [0.34972274]]\n",
      "700 \n",
      "cost: 0.69165105 \n",
      "w1: [[-0.7468783   0.34224826]\n",
      " [ 0.30054712 -1.0272706 ]] \n",
      "w2: [[0.36422268]\n",
      " [0.38396147]]\n",
      "800 \n",
      "cost: 0.69122905 \n",
      "w1: [[-0.75167656  0.3898845 ]\n",
      " [ 0.29908273 -1.0417612 ]] \n",
      "w2: [[0.36038664]\n",
      " [0.42261425]]\n",
      "900 \n",
      "cost: 0.6907082 \n",
      "w1: [[-0.7570658   0.4419769 ]\n",
      " [ 0.29866484 -1.0598632 ]] \n",
      "w2: [[0.35738835]\n",
      " [0.46607706]]\n",
      "1000 \n",
      "cost: 0.6900622 \n",
      "w1: [[-0.7631387   0.49893698]\n",
      " [ 0.2993223  -1.0823857 ]] \n",
      "w2: [[0.35539615]\n",
      " [0.5147873 ]]\n",
      "1100 \n",
      "cost: 0.689258 \n",
      "w1: [[-0.7700137   0.5611766 ]\n",
      " [ 0.30110958 -1.1102836 ]] \n",
      "w2: [[0.35463813]\n",
      " [0.56923217]]\n",
      "1200 \n",
      "cost: 0.68825215 \n",
      "w1: [[-0.7778396   0.6291111 ]\n",
      " [ 0.30411336 -1.1446697 ]] \n",
      "w2: [[0.35541642]\n",
      " [0.6299618 ]]\n",
      "1300 \n",
      "cost: 0.68698835 \n",
      "w1: [[-0.7868029  0.7031776]\n",
      " [ 0.3084615 -1.1868172]] \n",
      "w2: [[0.35812268]\n",
      " [0.69760984]]\n",
      "1400 \n",
      "cost: 0.68539125 \n",
      "w1: [[-0.7971412   0.7838668 ]\n",
      " [ 0.31433582 -1.2381439 ]] \n",
      "w2: [[0.36325443]\n",
      " [0.77292335]]\n",
      "1500 \n",
      "cost: 0.6833608 \n",
      "w1: [[-0.80915695  0.8717724 ]\n",
      " [ 0.3219898  -1.3001816 ]] \n",
      "w2: [[0.37143216]\n",
      " [0.8567975 ]]\n",
      "1600 \n",
      "cost: 0.68076444 \n",
      "w1: [[-0.82324207  0.9676526 ]\n",
      " [ 0.33177182 -1.3745104 ]] \n",
      "w2: [[0.38341722]\n",
      " [0.950304  ]]\n",
      "1700 \n",
      "cost: 0.67743087 \n",
      "w1: [[-0.83991086  1.0724753 ]\n",
      " [ 0.34415707 -1.462658  ]] \n",
      "w2: [[0.40013203]\n",
      " [1.0546957 ]]\n",
      "1800 \n",
      "cost: 0.6731472 \n",
      "w1: [[-0.85984516  1.1874151 ]\n",
      " [ 0.35978857 -1.5659497 ]] \n",
      "w2: [[0.42269003]\n",
      " [1.1713564 ]]\n",
      "1900 \n",
      "cost: 0.66766584 \n",
      "w1: [[-0.88395417  1.3137432 ]\n",
      " [ 0.37953117 -1.6853111 ]] \n",
      "w2: [[0.4524447]\n",
      " [1.3016655]]\n",
      "2000 \n",
      "cost: 0.6607224 \n",
      "w1: [[-0.9134525  1.4525877]\n",
      " [ 0.4045409 -1.8210503]] \n",
      "w2: [[0.4910671]\n",
      " [1.4467716]]\n",
      "2100 \n",
      "cost: 0.65206456 \n",
      "w1: [[-0.949952   1.6045859]\n",
      " [ 0.4363515 -1.9726576]] \n",
      "w2: [[0.5406595]\n",
      " [1.6073   ]]\n",
      "2200 \n",
      "cost: 0.64148396 \n",
      "w1: [[-0.9955614   1.7695262 ]\n",
      " [ 0.47697744 -2.1386795 ]] \n",
      "w2: [[0.6038922]\n",
      " [1.7830911]]\n",
      "2300 \n",
      "cost: 0.6288287 \n",
      "w1: [[-1.052976   1.9461553]\n",
      " [ 0.5290244 -2.3167262]] \n",
      "w2: [[0.6841395]\n",
      " [1.9730662]]\n",
      "2400 \n",
      "cost: 0.61397165 \n",
      "w1: [[-1.1255277  2.1322827]\n",
      " [ 0.595787  -2.50366  ]] \n",
      "w2: [[0.78556716]\n",
      " [2.175353  ]]\n",
      "2500 \n",
      "cost: 0.59672177 \n",
      "w1: [[-1.2171382  2.3251765]\n",
      " [ 0.6812931 -2.6959376]] \n",
      "w2: [[0.9131287]\n",
      " [2.387658 ]]\n",
      "2600 \n",
      "cost: 0.57669526 \n",
      "w1: [[-1.332079    2.5220764 ]\n",
      " [ 0.79022205 -2.8900278 ]] \n",
      "w2: [[1.0724028]\n",
      " [2.6077738]]\n",
      "2700 \n",
      "cost: 0.5532124 \n",
      "w1: [[-1.4743893  2.7205906]\n",
      " [ 0.9275555 -3.0827854]] \n",
      "w2: [[1.2691426]\n",
      " [2.8340034]]\n",
      "2800 \n",
      "cost: 0.5253311 \n",
      "w1: [[-1.6468223  2.9187686]\n",
      " [ 1.0977011 -3.2716331]] \n",
      "w2: [[1.5083127]\n",
      " [3.065293 ]]\n",
      "2900 \n",
      "cost: 0.4921548 \n",
      "w1: [[-1.8493804  3.1148694]\n",
      " [ 1.3028255 -3.4545496]] \n",
      "w2: [[1.7923905]\n",
      " [3.3009894]]\n",
      "3000 \n",
      "cost: 0.45345294 \n",
      "w1: [[-2.0779696  3.3070025]\n",
      " [ 1.540599  -3.629922 ]] \n",
      "w2: [[2.1191587]\n",
      " [3.5403435]]\n",
      "3100 \n",
      "cost: 0.41031042 \n",
      "w1: [[-2.3241463  3.4929488]\n",
      " [ 1.8026962 -3.79641  ]] \n",
      "w2: [[2.4801073]\n",
      " [3.7820427]]\n",
      "3200 \n",
      "cost: 0.36519644 \n",
      "w1: [[-2.5766623  3.6703172]\n",
      " [ 2.0759223 -3.9529223]] \n",
      "w2: [[2.8611286]\n",
      " [4.024017 ]]\n",
      "3300 \n",
      "cost: 0.32115638 \n",
      "w1: [[-2.8243022  3.8369381]\n",
      " [ 2.346044  -4.0987206]] \n",
      "w2: [[3.2459197]\n",
      " [4.2636127]]\n",
      "3400 \n",
      "cost: 0.28069124 \n",
      "w1: [[-3.0584447  3.9912841]\n",
      " [ 2.6018035 -4.2335186]] \n",
      "w2: [[3.6201904]\n",
      " [4.498028 ]]\n",
      "3500 \n",
      "cost: 0.24515033 \n",
      "w1: [[-3.2741148  4.132684 ]\n",
      " [ 2.8367074 -4.357492 ]] \n",
      "w2: [[3.9742243]\n",
      " [4.724804 ]]\n",
      "3600 \n",
      "cost: 0.21481812 \n",
      "w1: [[-3.4695687  4.261282 ]\n",
      " [ 3.0485182 -4.4711733]] \n",
      "w2: [[4.303095 ]\n",
      " [4.9421415]]\n",
      "3700 \n",
      "cost: 0.18932085 \n",
      "w1: [[-3.6452174  4.377806 ]\n",
      " [ 3.2377734 -4.5753236]] \n",
      "w2: [[4.6054993]\n",
      " [5.148978 ]]\n",
      "3800 \n",
      "cost: 0.16800654 \n",
      "w1: [[-3.802618   4.4833155]\n",
      " [ 3.4064102 -4.670802 ]] \n",
      "w2: [[4.8823204]\n",
      " [5.344898 ]]\n",
      "3900 \n",
      "cost: 0.15017782 \n",
      "w1: [[-3.9437656  4.5789847]\n",
      " [ 3.5568519 -4.7584796]] \n",
      "w2: [[5.135534]\n",
      " [5.529963]]\n",
      "4000 \n",
      "cost: 0.13520133 \n",
      "w1: [[-4.0706925  4.6659636]\n",
      " [ 3.6915228 -4.839181 ]] \n",
      "w2: [[5.367493]\n",
      " [5.704546]]\n",
      "4100 \n",
      "cost: 0.122541994 \n",
      "w1: [[-4.1852856  4.7453246]\n",
      " [ 3.812631  -4.913668 ]] \n",
      "w2: [[5.580579 ]\n",
      " [5.8692064]]\n",
      "4200 \n",
      "cost: 0.111764774 \n",
      "w1: [[-4.289206   4.818018 ]\n",
      " [ 3.9220946 -4.9826245]] \n",
      "w2: [[5.7769923]\n",
      " [6.0245852]]\n",
      "4300 \n",
      "cost: 0.10252113 \n",
      "w1: [[-4.3838935  4.884872 ]\n",
      " [ 4.021546  -5.046661 ]] \n",
      "w2: [[5.958708 ]\n",
      " [6.1713552]]\n",
      "4400 \n",
      "cost: 0.09453454 \n",
      "w1: [[-4.470565  4.946601]\n",
      " [ 4.112357 -5.106294]] \n",
      "w2: [[6.1274514]\n",
      " [6.3101797]]\n",
      "4500 \n",
      "cost: 0.08758484 \n",
      "w1: [[-4.5502505  5.003814 ]\n",
      " [ 4.195673  -5.161996 ]] \n",
      "w2: [[6.284717 ]\n",
      " [6.4416876]]\n",
      "4600 \n",
      "cost: 0.081496716 \n",
      "w1: [[-4.623825   5.057036 ]\n",
      " [ 4.2724605 -5.214171 ]] \n",
      "w2: [[6.4317904]\n",
      " [6.5664687]]\n",
      "4700 \n",
      "cost: 0.076129526 \n",
      "w1: [[-4.6920233  5.1067147]\n",
      " [ 4.3435254 -5.2631745]] \n",
      "w2: [[6.5697827]\n",
      " [6.6850643]]\n",
      "4800 \n",
      "cost: 0.07136994 \n",
      "w1: [[-4.755472  5.153237]\n",
      " [ 4.409555 -5.309317]] \n",
      "w2: [[6.6996503]\n",
      " [6.7979674]]\n",
      "4900 \n",
      "cost: 0.06712609 \n",
      "w1: [[-4.8147044  5.1969314]\n",
      " [ 4.471118  -5.352871 ]] \n",
      "w2: [[6.8222165]\n",
      " [6.9056273]]\n",
      "5000 \n",
      "cost: 0.06332273 \n",
      "w1: [[-4.870176   5.238087 ]\n",
      " [ 4.5287113 -5.3940716]] \n",
      "w2: [[6.9381986]\n",
      " [7.0084486]]\n",
      "5100 \n",
      "cost: 0.059897948 \n",
      "w1: [[-4.9222784  5.276948 ]\n",
      " [ 4.5827537 -5.43313  ]] \n",
      "w2: [[7.0482197]\n",
      " [7.1068063]]\n",
      "5200 \n",
      "cost: 0.056800485 \n",
      "w1: [[-4.971351  5.313731]\n",
      " [ 4.63361  -5.470232]] \n",
      "w2: [[7.1528234]\n",
      " [7.201029 ]]\n",
      "5300 \n",
      "cost: 0.053987607 \n",
      "w1: [[-5.0176864  5.3486257]\n",
      " [ 4.6815915 -5.5055423]] \n",
      "w2: [[7.252484 ]\n",
      " [7.2914186]]\n",
      "5400 \n",
      "cost: 0.051423408 \n",
      "w1: [[-5.0615396  5.381799 ]\n",
      " [ 4.726971  -5.5392056]] \n",
      "w2: [[7.3476267]\n",
      " [7.3782477]]\n",
      "5500 \n",
      "cost: 0.049077615 \n",
      "w1: [[-5.1031365  5.4133964]\n",
      " [ 4.7699885 -5.571355 ]] \n",
      "w2: [[7.4386206]\n",
      " [7.4617643]]\n",
      "5600 \n",
      "cost: 0.0469245 \n",
      "w1: [[-5.142673   5.4435463]\n",
      " [ 4.8108506 -5.602104 ]] \n",
      "w2: [[7.5257945]\n",
      " [7.54219  ]]\n",
      "5700 \n",
      "cost: 0.044942174 \n",
      "w1: [[-5.180322  5.472365]\n",
      " [ 4.84974  -5.631558]] \n",
      "w2: [[7.6094403]\n",
      " [7.619731 ]]\n",
      "5800 \n",
      "cost: 0.04311175 \n",
      "w1: [[-5.21624    5.4999537]\n",
      " [ 4.8868217 -5.659811 ]] \n",
      "w2: [[7.6898217]\n",
      " [7.694573 ]]\n",
      "5900 \n",
      "cost: 0.041416995 \n",
      "w1: [[-5.2505617  5.526407 ]\n",
      " [ 4.922237  -5.6869473]] \n",
      "w2: [[7.7671747]\n",
      " [7.766884 ]]\n",
      "6000 \n",
      "cost: 0.039843902 \n",
      "w1: [[-5.2834077  5.551804 ]\n",
      " [ 4.956116  -5.713044 ]] \n",
      "w2: [[7.8417063]\n",
      " [7.836821 ]]\n",
      "6100 \n",
      "cost: 0.038380183 \n",
      "w1: [[-5.3148894  5.576222 ]\n",
      " [ 4.988575  -5.738171 ]] \n",
      "w2: [[7.91361  ]\n",
      " [7.9045267]]\n",
      "6200 \n",
      "cost: 0.037015155 \n",
      "w1: [[-5.345104   5.599725 ]\n",
      " [ 5.0197153 -5.762389 ]] \n",
      "w2: [[7.983062]\n",
      " [7.970129]]\n",
      "6300 \n",
      "cost: 0.03573949 \n",
      "w1: [[-5.3741417  5.622375 ]\n",
      " [ 5.0496287 -5.7857575]] \n",
      "w2: [[8.050211 ]\n",
      " [8.0337515]]\n",
      "6400 \n",
      "cost: 0.034544956 \n",
      "w1: [[-5.4020815  5.6442266]\n",
      " [ 5.0784025 -5.808327 ]] \n",
      "w2: [[8.115204]\n",
      " [8.095498]]\n",
      "6500 \n",
      "cost: 0.033424187 \n",
      "w1: [[-5.428996   5.6653295]\n",
      " [ 5.106111  -5.8301473]] \n",
      "w2: [[8.178169]\n",
      " [8.155477]]\n",
      "6600 \n",
      "cost: 0.03237081 \n",
      "w1: [[-5.4549513  5.685729 ]\n",
      " [ 5.1328216 -5.851262 ]] \n",
      "w2: [[8.239226]\n",
      " [8.213778]]\n",
      "6700 \n",
      "cost: 0.03137914 \n",
      "w1: [[-5.480008   5.7054687]\n",
      " [ 5.158601  -5.871711 ]] \n",
      "w2: [[8.298484]\n",
      " [8.270489]]\n",
      "6800 \n",
      "cost: 0.030443855 \n",
      "w1: [[-5.5042205  5.7245855]\n",
      " [ 5.183503  -5.8915305]] \n",
      "w2: [[8.356042]\n",
      " [8.325692]]\n",
      "6900 \n",
      "cost: 0.029560588 \n",
      "w1: [[-5.5276394  5.7431145]\n",
      " [ 5.207581  -5.9107556]] \n",
      "w2: [[8.411996]\n",
      " [8.379461]]\n",
      "7000 \n",
      "cost: 0.028725132 \n",
      "w1: [[-5.550309  5.76109 ]\n",
      " [ 5.230883 -5.929419]] \n",
      "w2: [[8.466424]\n",
      " [8.431865]]\n",
      "7100 \n",
      "cost: 0.0279338 \n",
      "w1: [[-5.572275   5.7785397]\n",
      " [ 5.253453  -5.9475493]] \n",
      "w2: [[8.519412]\n",
      " [8.48297 ]]\n",
      "7200 \n",
      "cost: 0.027183339 \n",
      "w1: [[-5.593571   5.7954926]\n",
      " [ 5.2753315 -5.9651732]] \n",
      "w2: [[8.57103 ]\n",
      " [8.532838]]\n",
      "7300 \n",
      "cost: 0.026470631 \n",
      "w1: [[-5.6142373  5.811972 ]\n",
      " [ 5.2965584 -5.9823165]] \n",
      "w2: [[8.621342]\n",
      " [8.581522]]\n",
      "7400 \n",
      "cost: 0.02579302 \n",
      "w1: [[-5.6343055  5.8280053]\n",
      " [ 5.3171644 -5.999002 ]] \n",
      "w2: [[8.670414]\n",
      " [8.629075]]\n",
      "7500 \n",
      "cost: 0.025148053 \n",
      "w1: [[-5.6538076  5.8436112]\n",
      " [ 5.3371835 -6.015253 ]] \n",
      "w2: [[8.718304]\n",
      " [8.675548]]\n",
      "7600 \n",
      "cost: 0.024533462 \n",
      "w1: [[-5.6727695  5.858812 ]\n",
      " [ 5.356646  -6.031088 ]] \n",
      "w2: [[8.765067]\n",
      " [8.720987]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7700 \n",
      "cost: 0.023947135 \n",
      "w1: [[-5.691221   5.873626 ]\n",
      " [ 5.375578  -6.0465274]] \n",
      "w2: [[8.810754]\n",
      " [8.765437]]\n",
      "7800 \n",
      "cost: 0.023387231 \n",
      "w1: [[-5.709185   5.888072 ]\n",
      " [ 5.394007  -6.0615873]] \n",
      "w2: [[8.855411]\n",
      " [8.808938]]\n",
      "7900 \n",
      "cost: 0.022852123 \n",
      "w1: [[-5.7266855  5.9021664]\n",
      " [ 5.411957  -6.0762877]] \n",
      "w2: [[8.899082]\n",
      " [8.851526]]\n",
      "8000 \n",
      "cost: 0.022340167 \n",
      "w1: [[-5.743743   5.915924 ]\n",
      " [ 5.4294477 -6.0906415]] \n",
      "w2: [[8.941811]\n",
      " [8.893242]]\n",
      "8100 \n",
      "cost: 0.021849867 \n",
      "w1: [[-5.760379   5.9293613]\n",
      " [ 5.4465017 -6.1046634]] \n",
      "w2: [[8.983635]\n",
      " [8.934116]]\n",
      "8200 \n",
      "cost: 0.021380018 \n",
      "w1: [[-5.776611   5.942489 ]\n",
      " [ 5.463139  -6.1183686]] \n",
      "w2: [[9.024592]\n",
      " [8.97418 ]]\n",
      "8300 \n",
      "cost: 0.020929327 \n",
      "w1: [[-5.7924566  5.9553223]\n",
      " [ 5.4793777 -6.1317697]] \n",
      "w2: [[9.064718]\n",
      " [9.013469]]\n",
      "8400 \n",
      "cost: 0.020496655 \n",
      "w1: [[-5.8079324  5.967873 ]\n",
      " [ 5.495234  -6.144879 ]] \n",
      "w2: [[9.104042]\n",
      " [9.052009]]\n",
      "8500 \n",
      "cost: 0.02008098 \n",
      "w1: [[-5.8230553  5.9801517]\n",
      " [ 5.5107245 -6.1577077]] \n",
      "w2: [[9.142599]\n",
      " [9.089826]]\n",
      "8600 \n",
      "cost: 0.019681362 \n",
      "w1: [[-5.837838   5.9921703]\n",
      " [ 5.525865  -6.1702676]] \n",
      "w2: [[9.180414]\n",
      " [9.126946]]\n",
      "8700 \n",
      "cost: 0.019296862 \n",
      "w1: [[-5.8522944  6.0039372]\n",
      " [ 5.54067   -6.1825666]] \n",
      "w2: [[9.217518]\n",
      " [9.163397]]\n",
      "8800 \n",
      "cost: 0.01892668 \n",
      "w1: [[-5.86644    6.0154634]\n",
      " [ 5.5551524 -6.194616 ]] \n",
      "w2: [[9.253935]\n",
      " [9.199201]]\n",
      "8900 \n",
      "cost: 0.01857 \n",
      "w1: [[-5.8802834  6.026758 ]\n",
      " [ 5.569324  -6.2064257]] \n",
      "w2: [[9.28969 ]\n",
      " [9.234378]]\n",
      "9000 \n",
      "cost: 0.018226217 \n",
      "w1: [[-5.893839   6.0378275]\n",
      " [ 5.583198  -6.218004 ]] \n",
      "w2: [[9.324802]\n",
      " [9.268949]]\n",
      "9100 \n",
      "cost: 0.017894523 \n",
      "w1: [[-5.907117   6.048684 ]\n",
      " [ 5.596785  -6.2293577]] \n",
      "w2: [[9.359302]\n",
      " [9.302935]]\n",
      "9200 \n",
      "cost: 0.017574377 \n",
      "w1: [[-5.9201264  6.059331 ]\n",
      " [ 5.6100965 -6.2404976]] \n",
      "w2: [[9.393205]\n",
      " [9.336356]]\n",
      "9300 \n",
      "cost: 0.01726521 \n",
      "w1: [[-5.9328794  6.0697784]\n",
      " [ 5.6231413 -6.251428 ]] \n",
      "w2: [[9.426532]\n",
      " [9.369227]]\n",
      "9400 \n",
      "cost: 0.016966432 \n",
      "w1: [[-5.945384   6.0800333]\n",
      " [ 5.6359305 -6.262159 ]] \n",
      "w2: [[9.4593 ]\n",
      " [9.40157]]\n",
      "9500 \n",
      "cost: 0.016677534 \n",
      "w1: [[-5.9576483  6.0901003]\n",
      " [ 5.648473  -6.272695 ]] \n",
      "w2: [[9.49153 ]\n",
      " [9.433396]]\n",
      "9600 \n",
      "cost: 0.0163981 \n",
      "w1: [[-5.9696813  6.099989 ]\n",
      " [ 5.6607757 -6.2830434]] \n",
      "w2: [[9.52324 ]\n",
      " [9.464726]]\n",
      "9700 \n",
      "cost: 0.01612759 \n",
      "w1: [[-5.981491   6.1096997]\n",
      " [ 5.6728477 -6.293211 ]] \n",
      "w2: [[9.554445]\n",
      " [9.495573]]\n",
      "9800 \n",
      "cost: 0.015865648 \n",
      "w1: [[-5.993084   6.119244 ]\n",
      " [ 5.684698  -6.3032017]] \n",
      "w2: [[9.58516 ]\n",
      " [9.525951]]\n",
      "9900 \n",
      "cost: 0.0156119075 \n",
      "w1: [[-6.00447   6.128623]\n",
      " [ 5.696334 -6.313022]] \n",
      "w2: [[9.6154  ]\n",
      " [9.555875]]\n",
      "10000 \n",
      "cost: 0.015365919 \n",
      "w1: [[-6.015654   6.1378455]\n",
      " [ 5.7077627 -6.322678 ]] \n",
      "w2: [[9.645179]\n",
      " [9.585355]]\n",
      "\n",
      "hf: [[0.01796527]\n",
      " [0.9859585 ]\n",
      " [0.98647946]\n",
      " [0.01546053]] \n",
      "pre: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "acc: 1.0\n",
      "\n",
      "bias: [-3.1420841 -3.4148886] [-4.705673]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata,y:ydata})\n",
    "        if step % 100 == 0:\n",
    "            print(step, \"\\ncost:\",sess.run(cost, feed_dict={x:xdata,y:ydata}),\n",
    "                 \"\\nw1:\",sess.run(w1),\"\\nw2:\",sess.run(w2))\n",
    "    hv,pv,av=sess.run([hf, predicted, accuracy],feed_dict={x:xdata,y:ydata})\n",
    "    print(\"\\nhf:\",hv,\"\\npre:\",pv,\"\\nacc:\",av)\n",
    "    print(\"\\nbias:\",sess.run(b1), sess.run(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,2])\n",
    "y=tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,10]))\n",
    "b1=tf.Variable(tf.random_normal([10]))\n",
    "L1=tf.sigmoid(tf.matmul(x,w1)+b1) # [None,2]\n",
    "\n",
    "w2=tf.Variable(tf.random_normal([10,1]))\n",
    "b2=tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.sigmoid(tf.matmul(L1,w2)+b2)\n",
    "\n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted=tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 0.9844317\n",
      "100 cost: 0.6437523\n",
      "200 cost: 0.6031059\n",
      "300 cost: 0.55670464\n",
      "400 cost: 0.5064163\n",
      "500 cost: 0.4545452\n",
      "600 cost: 0.40254325\n",
      "700 cost: 0.3521511\n",
      "800 cost: 0.30520827\n",
      "900 cost: 0.26309937\n",
      "1000 cost: 0.22648169\n",
      "1100 cost: 0.19534582\n",
      "1200 cost: 0.1692406\n",
      "1300 cost: 0.14750783\n",
      "1400 cost: 0.12944749\n",
      "1500 cost: 0.114411235\n",
      "1600 cost: 0.10183892\n",
      "1700 cost: 0.09126656\n",
      "1800 cost: 0.08231797\n",
      "1900 cost: 0.07469198\n",
      "2000 cost: 0.06814814\n",
      "2100 cost: 0.062494986\n",
      "2200 cost: 0.05757954\n",
      "2300 cost: 0.05327902\n",
      "2400 cost: 0.049494453\n",
      "2500 cost: 0.04614561\n",
      "2600 cost: 0.043166913\n",
      "2700 cost: 0.04050474\n",
      "2800 cost: 0.03811447\n",
      "2900 cost: 0.035959393\n",
      "3000 cost: 0.03400854\n",
      "3100 cost: 0.032236025\n",
      "3200 cost: 0.030619906\n",
      "3300 cost: 0.029141542\n",
      "3400 cost: 0.027785063\n",
      "3500 cost: 0.026536813\n",
      "3600 cost: 0.025385069\n",
      "3700 cost: 0.024319584\n",
      "3800 cost: 0.023331493\n",
      "3900 cost: 0.022413142\n",
      "4000 cost: 0.021557715\n",
      "4100 cost: 0.020759325\n",
      "4200 cost: 0.020012699\n",
      "4300 cost: 0.019313158\n",
      "4400 cost: 0.018656658\n",
      "4500 cost: 0.018039394\n",
      "4600 cost: 0.017458245\n",
      "4700 cost: 0.016910207\n",
      "4800 cost: 0.01639265\n",
      "4900 cost: 0.015903223\n",
      "5000 cost: 0.015439815\n",
      "5100 cost: 0.015000373\n",
      "5200 cost: 0.014583311\n",
      "5300 cost: 0.014186967\n",
      "5400 cost: 0.013809835\n",
      "5500 cost: 0.013450731\n",
      "5600 cost: 0.013108319\n",
      "5700 cost: 0.012781589\n",
      "5800 cost: 0.012469528\n",
      "5900 cost: 0.012171113\n",
      "6000 cost: 0.011885622\n",
      "6100 cost: 0.011612227\n",
      "6200 cost: 0.011350108\n",
      "6300 cost: 0.011098786\n",
      "6400 cost: 0.010857441\n",
      "6500 cost: 0.01062566\n",
      "6600 cost: 0.010402862\n",
      "6700 cost: 0.01018853\n",
      "6800 cost: 0.009982191\n",
      "6900 cost: 0.00978348\n",
      "7000 cost: 0.009591926\n",
      "7100 cost: 0.009407224\n",
      "7200 cost: 0.009228992\n",
      "7300 cost: 0.009056899\n",
      "7400 cost: 0.008890684\n",
      "7500 cost: 0.008730013\n",
      "7600 cost: 0.00857466\n",
      "7700 cost: 0.008424397\n",
      "7800 cost: 0.0082789175\n",
      "7900 cost: 0.008138044\n",
      "8000 cost: 0.008001531\n",
      "8100 cost: 0.007869241\n",
      "8200 cost: 0.007740964\n",
      "8300 cost: 0.007616503\n",
      "8400 cost: 0.0074957367\n",
      "8500 cost: 0.0073784976\n",
      "8600 cost: 0.007264605\n",
      "8700 cost: 0.0071539367\n",
      "8800 cost: 0.0070463577\n",
      "8900 cost: 0.0069417916\n",
      "9000 cost: 0.006840072\n",
      "9100 cost: 0.0067410935\n",
      "9200 cost: 0.0066447654\n",
      "9300 cost: 0.0065509663\n",
      "9400 cost: 0.006459591\n",
      "9500 cost: 0.006370579\n",
      "9600 cost: 0.0062838537\n",
      "9700 cost: 0.0061992654\n",
      "9800 cost: 0.006116844\n",
      "9900 cost: 0.0060363924\n",
      "10000 cost: 0.0059579266\n",
      "\n",
      "hf: [[0.00503985]\n",
      " [0.9939791 ]\n",
      " [0.993771  ]\n",
      " [0.00647051]] \n",
      "pre: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata,y:ydata})\n",
    "        if step % 100 == 0:\n",
    "            print(step, \"cost:\",sess.run(cost, feed_dict={x:xdata,y:ydata}))\n",
    "    hv,pv,av=sess.run([hf, predicted, accuracy],feed_dict={x:xdata,y:ydata})\n",
    "    print(\"\\nhf:\",hv,\"\\npre:\",pv,\"\\nacc:\",av)\n",
    "#     print(\"\\nbias:\",sess.run(b1), sess.run(b2))\n",
    "## 층은 얇지만 층을 구성하는 노드를 넓게했더니 정확도가 많이 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep & wide 신경망 설계\n",
    "x=tf.placeholder(tf.float32,[None,2])\n",
    "y=tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,10]))\n",
    "b1=tf.Variable(tf.random_normal([10]))\n",
    "L1=tf.sigmoid(tf.matmul(x,w1)+b1) # [None,2]\n",
    "\n",
    "w2=tf.Variable(tf.random_normal([10,10]))\n",
    "b2=tf.Variable(tf.random_normal([10]))\n",
    "L2=tf.sigmoid(tf.matmul(L1,w2)+b2)\n",
    "\n",
    "w3=tf.Variable(tf.random_normal([10,10]))\n",
    "b3=tf.Variable(tf.random_normal([10]))\n",
    "L3=tf.sigmoid(tf.matmul(L2,w3)+b3)\n",
    "\n",
    "w4=tf.Variable(tf.random_normal([10,1]))\n",
    "b4=tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.sigmoid(tf.matmul(L3,w4)+b4)\n",
    "\n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted=tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 0.7030981\n",
      "100 cost: 0.6778734\n",
      "200 cost: 0.6549016\n",
      "300 cost: 0.62988794\n",
      "400 cost: 0.5960167\n",
      "500 cost: 0.54513264\n",
      "600 cost: 0.46884105\n",
      "700 cost: 0.36467153\n",
      "800 cost: 0.25124228\n",
      "900 cost: 0.16128802\n",
      "1000 cost: 0.10487891\n",
      "1100 cost: 0.072026104\n",
      "1200 cost: 0.052435793\n",
      "1300 cost: 0.04010418\n",
      "1400 cost: 0.031897858\n",
      "1500 cost: 0.026163904\n",
      "1600 cost: 0.021990336\n",
      "1700 cost: 0.018847926\n",
      "1800 cost: 0.016414322\n",
      "1900 cost: 0.014484687\n",
      "2000 cost: 0.012923902\n",
      "2100 cost: 0.011639786\n",
      "2200 cost: 0.010567628\n",
      "2300 cost: 0.009661113\n",
      "2400 cost: 0.008886004\n",
      "2500 cost: 0.008216734\n",
      "2600 cost: 0.0076338057\n",
      "2700 cost: 0.007122104\n",
      "2800 cost: 0.0066697574\n",
      "2900 cost: 0.006267417\n",
      "3000 cost: 0.0059074513\n",
      "3100 cost: 0.0055837603\n",
      "3200 cost: 0.0052912896\n",
      "3300 cost: 0.005025849\n",
      "3400 cost: 0.0047840024\n",
      "3500 cost: 0.0045628576\n",
      "3600 cost: 0.004359917\n",
      "3700 cost: 0.0041730436\n",
      "3800 cost: 0.0040005837\n",
      "3900 cost: 0.0038408686\n",
      "4000 cost: 0.0036926363\n",
      "4100 cost: 0.0035546701\n",
      "4200 cost: 0.003426053\n",
      "4300 cost: 0.003305811\n",
      "4400 cost: 0.003193222\n",
      "4500 cost: 0.0030876263\n",
      "4600 cost: 0.0029883045\n",
      "4700 cost: 0.002894866\n",
      "4800 cost: 0.0028066959\n",
      "4900 cost: 0.00272342\n",
      "5000 cost: 0.002644738\n",
      "5100 cost: 0.0025701406\n",
      "5200 cost: 0.0024994032\n",
      "5300 cost: 0.0024321962\n",
      "5400 cost: 0.002368399\n",
      "5500 cost: 0.0023076083\n",
      "5600 cost: 0.0022497035\n",
      "5700 cost: 0.0021944905\n",
      "5800 cost: 0.0021417146\n",
      "5900 cost: 0.0020913605\n",
      "6000 cost: 0.0020431294\n",
      "6100 cost: 0.001996991\n",
      "6200 cost: 0.0019527508\n",
      "6300 cost: 0.0019103044\n",
      "6400 cost: 0.0018696212\n",
      "6500 cost: 0.0018304774\n",
      "6600 cost: 0.0017928728\n",
      "6700 cost: 0.0017567474\n",
      "6800 cost: 0.001721952\n",
      "6900 cost: 0.0016884262\n",
      "7000 cost: 0.001656096\n",
      "7100 cost: 0.0016249309\n",
      "7200 cost: 0.0015948561\n",
      "7300 cost: 0.0015658272\n",
      "7400 cost: 0.0015377692\n",
      "7500 cost: 0.0015106671\n",
      "7600 cost: 0.0014844164\n",
      "7700 cost: 0.0014590318\n",
      "7800 cost: 0.0014344986\n",
      "7900 cost: 0.0014106524\n",
      "8000 cost: 0.0013876425\n",
      "8100 cost: 0.0013652745\n",
      "8200 cost: 0.0013435936\n",
      "8300 cost: 0.0013225547\n",
      "8400 cost: 0.0013021429\n",
      "8500 cost: 0.0012823135\n",
      "8600 cost: 0.0012630364\n",
      "8700 cost: 0.0012443417\n",
      "8800 cost: 0.001226095\n",
      "8900 cost: 0.0012084303\n",
      "9000 cost: 0.0011911837\n",
      "9100 cost: 0.0011744446\n",
      "9200 cost: 0.0011580938\n",
      "9300 cost: 0.0011422355\n",
      "9400 cost: 0.0011267504\n",
      "9500 cost: 0.0011116682\n",
      "9600 cost: 0.0010969593\n",
      "9700 cost: 0.0010825788\n",
      "9800 cost: 0.0010686163\n",
      "9900 cost: 0.0010549373\n",
      "10000 cost: 0.0010416462\n",
      "\n",
      "hf: [[0.0010708 ]\n",
      " [0.9989537 ]\n",
      " [0.99910754]\n",
      " [0.00115484]] \n",
      "pre: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata,y:ydata})\n",
    "        if step % 100 == 0:\n",
    "            print(step, \"cost:\",sess.run(cost, feed_dict={x:xdata,y:ydata}))\n",
    "    hv,pv,av=sess.run([hf, predicted, accuracy],feed_dict={x:xdata,y:ydata})\n",
    "    print(\"\\nhf:\",hv,\"\\npre:\",pv,\"\\nacc:\",av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep & wide 설계\n",
    "x=tf.placeholder(tf.float32,[None,2])\n",
    "y=tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,10]))\n",
    "b1=tf.Variable(tf.random_normal([10]))\n",
    "L1=tf.sigmoid(tf.matmul(x,w1)+b1) # [None,2]\n",
    "\n",
    "w2=tf.Variable(tf.random_normal([10,10]))\n",
    "b2=tf.Variable(tf.random_normal([10]))\n",
    "L2=tf.sigmoid(tf.matmul(L1,w2)+b2)\n",
    "\n",
    "w3=tf.Variable(tf.random_normal([10,10]))\n",
    "b3=tf.Variable(tf.random_normal([10]))\n",
    "L3=tf.sigmoid(tf.matmul(L2,w3)+b3)\n",
    "\n",
    "w4=tf.Variable(tf.random_normal([10,10]))\n",
    "b4=tf.Variable(tf.random_normal([10]))\n",
    "L4=tf.sigmoid(tf.matmul(L3,w4)+b4)\n",
    "\n",
    "w5=tf.Variable(tf.random_normal([10,10]))\n",
    "b5=tf.Variable(tf.random_normal([10]))\n",
    "L5=tf.sigmoid(tf.matmul(L4,w5)+b5)\n",
    "\n",
    "w6=tf.Variable(tf.random_normal([10,10]))\n",
    "b6=tf.Variable(tf.random_normal([10]))\n",
    "L6=tf.sigmoid(tf.matmul(L5,w6)+b6)\n",
    "\n",
    "w7=tf.Variable(tf.random_normal([10,10]))\n",
    "b7=tf.Variable(tf.random_normal([10]))\n",
    "L7=tf.sigmoid(tf.matmul(L6,w7)+b7)\n",
    "\n",
    "w8=tf.Variable(tf.random_normal([10,10]))\n",
    "b8=tf.Variable(tf.random_normal([10]))\n",
    "L8=tf.sigmoid(tf.matmul(L7,w8)+b8)\n",
    "\n",
    "w9=tf.Variable(tf.random_normal([10,10]))\n",
    "b9=tf.Variable(tf.random_normal([10]))\n",
    "L9=tf.sigmoid(tf.matmul(L8,w9)+b9)\n",
    "\n",
    "w10=tf.Variable(tf.random_normal([10,1]))\n",
    "b10=tf.Variable(tf.random_normal([1]))\n",
    "hf=tf.sigmoid(tf.matmul(L9,w10)+b10)\n",
    "\n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted=tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 0.9495955\n",
      "100 cost: 0.6931598\n",
      "200 cost: 0.6931596\n",
      "300 cost: 0.69315946\n",
      "400 cost: 0.6931594\n",
      "500 cost: 0.6931593\n",
      "600 cost: 0.69315904\n",
      "700 cost: 0.6931589\n",
      "800 cost: 0.6931587\n",
      "900 cost: 0.69315875\n",
      "1000 cost: 0.6931585\n",
      "1100 cost: 0.6931584\n",
      "1200 cost: 0.69315827\n",
      "1300 cost: 0.69315815\n",
      "1400 cost: 0.69315803\n",
      "1500 cost: 0.6931579\n",
      "1600 cost: 0.6931578\n",
      "1700 cost: 0.6931576\n",
      "1800 cost: 0.69315743\n",
      "1900 cost: 0.6931573\n",
      "2000 cost: 0.69315714\n",
      "2100 cost: 0.6931571\n",
      "2200 cost: 0.69315696\n",
      "2300 cost: 0.69315684\n",
      "2400 cost: 0.6931568\n",
      "2500 cost: 0.6931565\n",
      "2600 cost: 0.69315636\n",
      "2700 cost: 0.69315624\n",
      "2800 cost: 0.69315624\n",
      "2900 cost: 0.69315606\n",
      "3000 cost: 0.69315594\n",
      "3100 cost: 0.6931559\n",
      "3200 cost: 0.6931557\n",
      "3300 cost: 0.6931556\n",
      "3400 cost: 0.6931554\n",
      "3500 cost: 0.69315535\n",
      "3600 cost: 0.69315517\n",
      "3700 cost: 0.6931552\n",
      "3800 cost: 0.69315505\n",
      "3900 cost: 0.69315493\n",
      "4000 cost: 0.69315475\n",
      "4100 cost: 0.6931547\n",
      "4200 cost: 0.69315445\n",
      "4300 cost: 0.69315445\n",
      "4400 cost: 0.6931543\n",
      "4500 cost: 0.6931542\n",
      "4600 cost: 0.693154\n",
      "4700 cost: 0.693154\n",
      "4800 cost: 0.6931538\n",
      "4900 cost: 0.6931536\n",
      "5000 cost: 0.69315356\n",
      "5100 cost: 0.6931535\n",
      "5200 cost: 0.6931533\n",
      "5300 cost: 0.69315326\n",
      "5400 cost: 0.69315314\n",
      "5500 cost: 0.693153\n",
      "5600 cost: 0.69315296\n",
      "5700 cost: 0.6931528\n",
      "5800 cost: 0.69315267\n",
      "5900 cost: 0.69315255\n",
      "6000 cost: 0.6931525\n",
      "6100 cost: 0.6931523\n",
      "6200 cost: 0.6931522\n",
      "6300 cost: 0.6931521\n",
      "6400 cost: 0.693152\n",
      "6500 cost: 0.69315195\n",
      "6600 cost: 0.69315183\n",
      "6700 cost: 0.6931517\n",
      "6800 cost: 0.6931516\n",
      "6900 cost: 0.6931516\n",
      "7000 cost: 0.6931514\n",
      "7100 cost: 0.69315124\n",
      "7200 cost: 0.6931512\n",
      "7300 cost: 0.693151\n",
      "7400 cost: 0.693151\n",
      "7500 cost: 0.6931508\n",
      "7600 cost: 0.6931508\n",
      "7700 cost: 0.69315064\n",
      "7800 cost: 0.69315046\n",
      "7900 cost: 0.6931504\n",
      "8000 cost: 0.69315034\n",
      "8100 cost: 0.6931502\n",
      "8200 cost: 0.69315016\n",
      "8300 cost: 0.6931501\n",
      "8400 cost: 0.69314986\n",
      "8500 cost: 0.6931499\n",
      "8600 cost: 0.6931498\n",
      "8700 cost: 0.6931496\n",
      "8800 cost: 0.6931496\n",
      "8900 cost: 0.6931493\n",
      "9000 cost: 0.6931494\n",
      "9100 cost: 0.6931492\n",
      "9200 cost: 0.6931492\n",
      "9300 cost: 0.6931491\n",
      "9400 cost: 0.693149\n",
      "9500 cost: 0.6931489\n",
      "9600 cost: 0.69314873\n",
      "9700 cost: 0.6931487\n",
      "9800 cost: 0.6931485\n",
      "9900 cost: 0.69314855\n",
      "10000 cost: 0.6931484\n",
      "\n",
      "hf: [[0.50002056]\n",
      " [0.4999745 ]\n",
      " [0.5000232 ]\n",
      " [0.4999795 ]] \n",
      "pre: [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]] \n",
      "acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata,y:ydata})\n",
    "        if step % 100 == 0:\n",
    "            print(step, \"cost:\",sess.run(cost, feed_dict={x:xdata,y:ydata}))\n",
    "    hv,pv,av=sess.run([hf, predicted, accuracy],feed_dict={x:xdata,y:ydata})\n",
    "    print(\"\\nhf:\",hv,\"\\npre:\",pv,\"\\nacc:\",av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist -> deep & wide 설계 => 정확도 90% 이상"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
