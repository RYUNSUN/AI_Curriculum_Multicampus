{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 머신러닝 프로젝트 수행과정\n",
    "1. 문제 정의\n",
    "    - 프로젝트 목적 : 회원 증가, 카드매출 증대, 생산비용 절감(불량 원인 찾는 작업)\n",
    "2. 머신러닝을 사용하지 않는 방법 검토\n",
    "    - 자동 테스트 어려움, 데이터 의존관계 복잡\n",
    "    - 처리 파이프라인 구조 복잡\n",
    "3. 시스템 설계\n",
    "    - 예측 결과를 어떻게 사용\n",
    "    - 예측 오류의 영향 고려\n",
    "    - 목표 성능, 포기 지점 설정\n",
    "4. 알고리즘 선택\n",
    "    - 군집화 -> 시각화 -> 알고리즘 고민\n",
    "5. 특징, 로그, 설계\n",
    "    - 수치벡터, 내일 날씨:비?\n",
    "    - 특징 변환 : 흐림(1), 맑은 (0)  \n",
    "      범주 -> 수치 (더미 변수):LableEncoder, OneHotEncoder\n",
    "6. 데이터 전처리\n",
    "    - 이상치 처리, 정규화, 빈도가 낮은 단어 제거, 더미변수화, 잡음 제거\n",
    "7. 학습 및 파라미터 튜닝\n",
    "    - 과적합 방지(교차검증)\n",
    "    - 규제화 \n",
    "    - 학습 곡선\n",
    "8. 시스템 통합\n",
    "    - 모니터링\n",
    "    \n",
    "### 2. 머신러닝 시스템 문제 해결\n",
    "- 확률 -> 자동테스트가 어렵다  \n",
    "- 예측 성능 ↑ => 시스템 복잡 => 유지보수 어려움  \n",
    "※ 시스템 변화에 잘 대응하는 머신러닝 시스템 구축하는게 목표 \n",
    "- 예측 모델 -> 모듈화 -> A/B 테스트 수행\n",
    "- 여러 모델을 모듈화 => 병렬 테스트 \n",
    "\n",
    "#### 머신러닝 알고리즘 선택 방법\n",
    "- 분류 : 클래스 (나이브 베이지안, 은닉 마르코프 모델)\n",
    "- 회귀 : 수치\n",
    "- 군집화\n",
    "- 차원축소\n",
    "- 추천\n",
    "- 이상탐지\n",
    "- 강화학습 : 정답이 명확하지 않은 환경에서 앞으로 취하게 될 최적의 행동 선택 \n",
    "\n",
    "#### 개념\n",
    "- 퍼셉트론 : 온라인 학습 방식, \"선형 분리(초평면)\" 가능 문제 해결 가능\n",
    "- cost 함수 : (실제값-예측값)^2\n",
    "- 힌지 손실 (hinge=경첩)\n",
    "- 규제화 : cost도 최소화하고 동시에 가중치도 작게 해줌으로써 과대적합이 되지 않도록 모델을 강제로 제한한다는 의미 (L1, L2 Regularization)\n",
    "- 신경망\n",
    "    - 비선형 data 분리 가능\n",
    "    - 시간 오래 걸림\n",
    "    - 변수 ↑ => 과적합 ↑\n",
    "- k-means\n",
    "- 의사 결정 트리\n",
    "\n",
    "### 3. 분류 결과 평가 방법\n",
    "(1) 분류 결과 평가 방법\n",
    " - 정밀도, 재현율, f 측정값, 정확도\n",
    " - 정확도 : 정답 일치 data / 전제 data\n",
    " - 정밀도(precision) : 분류기 -> 스팸으로 판정된 메일 중에서 진짜 스팸의 비율  \n",
    " ex) 전체 mail : 100, 스팸으로 판정한 메일:80, 진짜 스팸:60 => 60/80\n",
    " - 재현율(recall) : 실제 스팸(60개) 중 분류기가 분류기가 스팸으로 분류(50개) => 50/60\n",
    " - f-점수 : 정밀도와 재현율의 조화 평균\n",
    " \n",
    "(2) 예측 결과 평가 방법\n",
    " - 평균제곱요차(RMSE)\n",
    " - 결정 계수 : 항상 평균을 출력하는 예측 모델보다 성능이 더 좋은가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.arange(0, 4*2*4)\n",
    "len(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7]],\n",
       "\n",
       "       [[ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]],\n",
       "\n",
       "       [[16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26, 27],\n",
       "        [28, 29, 30, 31]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=arr.reshape([4,2,4])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.ndim # 3: 차원의 개수 \n",
    "v.sum() # 496 : 모든 요소의 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(axis=0) # 각 행 요소의 합\n",
    "v.shape #(4, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  6,  8, 10],\n",
       "       [20, 22, 24, 26],\n",
       "       [36, 38, 40, 42],\n",
       "       [52, 54, 56, 58]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(axis=1) # 각 열 요소의 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,  22],\n",
       "       [ 38,  54],\n",
       "       [ 70,  86],\n",
       "       [102, 118]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(axis=2) # 각 깊이 요소의 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.dynamic_rnn => tf.transepose(대상, [0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTensor=np.arange(2*3*4).reshape(2,3,4)\n",
    "myTensor\n",
    "myTensor.shape #(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0, 12],\n",
       "        [ 4, 16],\n",
       "        [ 8, 20]],\n",
       "\n",
       "       [[ 1, 13],\n",
       "        [ 5, 17],\n",
       "        [ 9, 21]],\n",
       "\n",
       "       [[ 2, 14],\n",
       "        [ 6, 18],\n",
       "        [10, 22]],\n",
       "\n",
       "       [[ 3, 15],\n",
       "        [ 7, 19],\n",
       "        [11, 23]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(myTensor).shape # (4, 3, 2)\n",
    "np.transpose(myTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(myTensor,[1,2,0]).shape # (2,3,4) -> (3,4,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras_mnist based RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:45:53.847342  5456 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist2/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist2/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist2/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist2/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"./mnist2/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "total_epoch=30\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=28 # 가로 픽셀수\n",
    "n_step=28  # 세로 픽셀수(입력단계, step)\n",
    "n_hidden=128 \n",
    "n_class=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_class])\n",
    "w = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "# Y: [batch_size, nclass]\n",
    "# outputs: [batch_size, n_step, n_hidden]\n",
    "# [n_step, batch_size, n_hidden]\n",
    "# [batch_size, n_hidden]\n",
    "outputs = tf.transpose(outputs, [1, 0, 2]) # [n_step, batch_size, n_hidden]\n",
    "outputs = outputs[-1] # [batch_size, n_hidden]\n",
    "model = tf.matmul(outputs, w) + b\n",
    "# tf.matmul([batch_size, n_hidden], [n_hidden, n_class])\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     1 avg cost 0.553\n",
      "epoch     2 avg cost 0.234\n",
      "epoch     3 avg cost 0.175\n",
      "epoch     4 avg cost 0.155\n",
      "epoch     5 avg cost 0.139\n",
      "epoch     6 avg cost 0.119\n",
      "epoch     7 avg cost 0.116\n",
      "epoch     8 avg cost 0.120\n",
      "epoch     9 avg cost 0.104\n",
      "epoch    10 avg cost 0.105\n",
      "epoch    11 avg cost 0.097\n",
      "epoch    12 avg cost 0.090\n",
      "epoch    13 avg cost 0.091\n",
      "epoch    14 avg cost 0.083\n",
      "epoch    15 avg cost 0.079\n",
      "epoch    16 avg cost 0.074\n",
      "epoch    17 avg cost 0.084\n",
      "epoch    18 avg cost 0.081\n",
      "epoch    19 avg cost 0.078\n",
      "epoch    20 avg cost 0.075\n",
      "epoch    21 avg cost 0.071\n",
      "epoch    22 avg cost 0.070\n",
      "epoch    23 avg cost 0.067\n",
      "epoch    24 avg cost 0.070\n",
      "epoch    25 avg cost 0.064\n",
      "epoch    26 avg cost 0.067\n",
      "epoch    27 avg cost 0.072\n",
      "epoch    28 avg cost 0.069\n",
      "epoch    29 avg cost 0.059\n",
      "epoch    30 avg cost 0.056\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # [batch_size, n_step, n_input]\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "        _, cv = sess.run([optimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        total_cost += cv\n",
    "    print(\"epoch \", \"%4d\" % (epoch+1),\n",
    "         \"avg cost\", \"{:.3f}\".format(total_cost/total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.965\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys = mnist.test.labels\n",
    "\n",
    "print(\"정확도: \", sess.run(accuracy, feed_dict={x: test_xs, y: test_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19,\n",
       " 'u': 20,\n",
       " 'v': 21,\n",
       " 'w': 22,\n",
       " 'x': 23,\n",
       " 'y': 24,\n",
       " 'z': 25}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'a':0,....,'z':25}\n",
    "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
    "            'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "            'v', 'w', 'x', 'y', 'z']\n",
    "num_dic={n:i for i,n in enumerate(char_arr)}\n",
    "num_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'test','free','make','show','take','four'}\n",
    "# 입력 : tes(3글자)\n",
    "# 출력 : est(1글자)\n",
    "# 1. 단어를 글자단위(voc)로 나눔. 원핫인코딩\n",
    "# 2. 트레이닝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
