{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model=Sequential()  \n",
    "model.add(Embedding(voc,hidden_size,input_length))  \n",
    "model.add(Dense(2, input_dim=4, init='uniform',activaition='linear'))  \n",
    "model=Sequential()  \n",
    "model.add(Dense(4, input_dim=10, init='normal',activation='relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "model.summary() : 요약정보  \n",
    "model.compile() : 함수설정  \n",
    "model.fit() : 학습  \n",
    "model.evaluate() : 모델 평가  \n",
    "model.predict() : 예측  \n",
    "model.save(), load_model(): 모델 저장 & 불러오기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x15d35f09be0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ # 텐서플로우 버전\n",
    "tf.get_default_graph() # 기본 그래프 정보 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGraph=tf.Graph() #사용자 그래프 생성\n",
    "with testGraph.as_default(): # 사용자 그래프에 노드 정의\n",
    "    x=tf.constant(10)\n",
    "    y=x+20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Session():세선객체생성, 분산처리환경 노드를 연결\n",
    "# run():연산 수행 -> 결과를 리턴\n",
    "# close():세선 종료\n",
    "x=tf.constant(5)\n",
    "y=x+10\n",
    "sess=tf.Session()\n",
    "print(sess.run(x))\n",
    "print(sess.run(y))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # 특별히 그래프를 지정하지 않았으므로, 기본 그래프를 사용해서 세션을 실행\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=testGraph) as sess: \n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess=tf.InteractiveSession()\n",
    "# x.eval()\n",
    "# y.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'var1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1=tf.Variable(5, name=\"var1\")\n",
    "var2=tf.add(var1,5, name=\"var2\")\n",
    "var1.op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns1_3/var3\n"
     ]
    }
   ],
   "source": [
    "# 이름공간(name space, 폴더와 비슷)을 이용한 노드 이름 중복 방지\n",
    "# tf.name_space():이름 공간 생성\n",
    "with tf.name_scope(\"ns1\"):\n",
    "    v3=tf.Variable(1, name=\"var3\")\n",
    "    v4=tf.add(v3,2,name=\"var4\")\n",
    "print(v3.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 1.6112338 prediction: [[2 2 2 1 1 1]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeiii\n",
      "step: 1 cost: 1.6168083 prediction: [[2 2 2 2 2 2]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeee\n",
      "step: 2 cost: 1.6073672 prediction: [[2 2 2 2 2 2]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeee\n",
      "step: 3 cost: 1.6017066 prediction: [[2 2 2 2 2 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeeh\n",
      "step: 4 cost: 1.586414 prediction: [[2 2 2 2 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeehh\n",
      "step: 5 cost: 1.5756149 prediction: [[2 2 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeehhh\n",
      "step: 6 cost: 1.5621663 prediction: [[2 2 2 2 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeehh\n",
      "step: 7 cost: 1.544249 prediction: [[2 2 2 2 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeehh\n",
      "step: 8 cost: 1.5267744 prediction: [[2 2 2 2 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeehh\n",
      "step: 9 cost: 1.508956 prediction: [[2 2 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeehhh\n",
      "step: 10 cost: 1.4915051 prediction: [[2 2 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeehhh\n",
      "step: 11 cost: 1.4715738 prediction: [[2 2 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeehhh\n",
      "step: 12 cost: 1.4492897 prediction: [[2 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehhh\n",
      "step: 13 cost: 1.4327747 prediction: [[2 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehhh\n",
      "step: 14 cost: 1.4172999 prediction: [[2 0 2 0 2 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eheheh\n",
      "step: 15 cost: 1.4235792 prediction: [[2 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehhh\n",
      "step: 16 cost: 1.390893 prediction: [[2 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehhh\n",
      "step: 17 cost: 1.377834 prediction: [[2 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehhh\n",
      "step: 18 cost: 1.3646301 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 19 cost: 1.3569757 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 20 cost: 1.3543857 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 21 cost: 1.3521868 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 22 cost: 1.3503388 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 23 cost: 1.348785 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 24 cost: 1.3474811 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 25 cost: 1.3463945 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 26 cost: 1.345499 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 27 cost: 1.3447686 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 28 cost: 1.3441781 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 29 cost: 1.3437024 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 30 cost: 1.3433203 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 31 cost: 1.3430123 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 32 cost: 1.3427634 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 33 cost: 1.3425612 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 34 cost: 1.3423958 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 35 cost: 1.3422598 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 36 cost: 1.3421469 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 37 cost: 1.3420528 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 38 cost: 1.3419734 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 39 cost: 1.3419065 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 40 cost: 1.3418493 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 41 cost: 1.3418003 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 42 cost: 1.3417583 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 43 cost: 1.3417215 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 44 cost: 1.3416897 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 45 cost: 1.3416618 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 46 cost: 1.3416371 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 47 cost: 1.3416153 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 48 cost: 1.341596 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 49 cost: 1.3415788 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 50 cost: 1.3415632 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 51 cost: 1.3415494 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 52 cost: 1.3415369 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 53 cost: 1.3415254 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 54 cost: 1.3415152 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 55 cost: 1.3415059 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 56 cost: 1.3414971 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 57 cost: 1.3414893 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 58 cost: 1.341482 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 59 cost: 1.3414754 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 60 cost: 1.3414692 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 61 cost: 1.3414634 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 62 cost: 1.341458 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 63 cost: 1.3414531 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 64 cost: 1.3414483 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 65 cost: 1.3414439 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 66 cost: 1.3414398 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 67 cost: 1.3414359 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 68 cost: 1.3414322 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 69 cost: 1.3414288 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 70 cost: 1.3414254 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 71 cost: 1.3414222 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 72 cost: 1.3414192 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 73 cost: 1.3414164 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 74 cost: 1.3414135 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 75 cost: 1.341411 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 76 cost: 1.3414084 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 77 cost: 1.341406 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 78 cost: 1.3414036 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 79 cost: 1.3414012 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 80 cost: 1.3413992 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 81 cost: 1.3413969 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 82 cost: 1.3413949 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 83 cost: 1.3413929 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 84 cost: 1.341391 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 85 cost: 1.3413891 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 86 cost: 1.3413872 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 87 cost: 1.3413854 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 88 cost: 1.3413836 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 89 cost: 1.3413819 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 90 cost: 1.3413801 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 91 cost: 1.3413786 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 92 cost: 1.3413768 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 93 cost: 1.3413752 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 94 cost: 1.3413738 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 95 cost: 1.3413721 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 96 cost: 1.3413706 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 97 cost: 1.3413692 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 98 cost: 1.3413677 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 99 cost: 1.3413662 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n",
      "step: 100 cost: 1.3413649 prediction: [[0 0 2 0 0 0]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehhh\n"
     ]
    }
   ],
   "source": [
    "# 입력 4개 -> 출력 2개 (hidden_size)\n",
    "\n",
    "# \"hihello\"\n",
    "# \"hihell\" => 입력\n",
    "# \"ihello\" => 출력\n",
    "# time_step:6, input_dim:5(전체 vocab(hihello로 만들어진) 사이즈), hidden_size:5\n",
    "\n",
    "idx2char=[\"h\",\"i\",\"e\",\"l\",\"o\"] # hihello에 set 함수를 쓰면 이렇게 나옴\n",
    "# 원래는 set 함수를 활용해 분리 후 원핫인코딩(to_categorical)으로 표현해야함\n",
    "xdata=[[0,1,0,2,3,3]]# xdata=\"hihell\"를 인덱스로 표현\n",
    "x_onehot=[[\n",
    "    [1,0,0,0,0],\n",
    "    [0,1,0,0,0],\n",
    "    [1,0,0,0,0],\n",
    "    [0,0,1,0,0],\n",
    "    [0,0,0,1,0],\n",
    "    [0,0,0,1,0]]]\n",
    "ydata=[[1,0,2,3,3,4]] # \"ihello\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes=5\n",
    "input_dim=5 # 입력데이터의 차원(단어벡터의 개수)\n",
    "hidden_size=5\n",
    "batch_size=1\n",
    "sequence_lentgh=6 #hihell까지 입력되므로 6글자\n",
    "learning_rate=0.1\n",
    "\n",
    "x=tf.placeholder(tf.float32, [None,sequence_lentgh, input_dim])\n",
    "y=tf.placeholder(tf.int32, [None,sequence_lentgh])\n",
    "\n",
    "\n",
    "#### 일반적으로 고정되는 코드들\n",
    "cell=tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)  # num_units는 출력개수\n",
    "ini_state = cell.zero_state(batch_size, tf.float32) # 가중치 초기상태 설정\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x, initial_state = ini_state, dtype = tf.float32)\n",
    "# outputs : 위로 올라가는 것, states : 현재 상태\n",
    "\n",
    "x_fc=tf.reshape(outputs,[-1, hidden_size])\n",
    "outputs=tf.contrib.layers.fully_connected(inputs=x_fc, num_outputs=num_classes)\n",
    "outputs=tf.reshape(outputs,[batch_size, sequence_lentgh, num_classes])\n",
    "#                          [1, 6, 5]=>[[[0.1,0.2,0.5,0.1,0.1]],[],[]]\n",
    "\n",
    "weights=tf.ones([batch_size, sequence_lentgh])\n",
    "sequence_loss=tf.contrib.seq2seq.sequence_loss(logits=outputs,targets=y, weights=weights)\n",
    "loss=tf.reduce_mean(sequence_loss)\n",
    "\n",
    "prediction= tf.argmax(outputs, axis=2) # outputs에서 prediction은 num_classes로 axis=2로 줘야함\n",
    "\n",
    "train=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(101):\n",
    "        lv, _=sess.run([loss, train], \n",
    "                       feed_dict={x:x_onehot, y:ydata})\n",
    "        res=sess.run(prediction, feed_dict={x:x_onehot})\n",
    "        print(\"step:\", i, \"cost:\",lv, \"prediction:\",res,\n",
    "              \"true Y:\", ydata)\n",
    "        # prediction:[[1 0 2 2 3 1]] true Y:[1 0 2 3 3 4]\n",
    "        # .....\n",
    "        # prediction:[[1 0 2 3 3 4]] true Y:[1 0 2 3 3 4]\n",
    "        resStr=[idx2char[c] for c in np.squeeze(res)]\n",
    "        print(\"predction str:\",\"\".join(resStr))\n",
    "        \n",
    "        \n",
    "# 학습 hihell -> ihello를 출력하고 싶음\n",
    "# 훈련과정 \n",
    "# hihell -> elhill \n",
    "# ....\n",
    "# hihell -> ihehho\n",
    "# ....\n",
    "# hihell -> ihello (many to many)\n",
    "# 만약 many to one으로 출력하면 hihell -> o 이렇게 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 1.6160024 prediction: [[4 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: oeeeoo\n",
      "step: 1 cost: 1.576425 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 2 cost: 1.542451 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 3 cost: 1.4947838 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 4 cost: 1.445278 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 5 cost: 1.4093639 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 6 cost: 1.374883 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 7 cost: 1.3337227 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 8 cost: 1.3077408 prediction: [[2 2 2 2 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeeeoo\n",
      "step: 9 cost: 1.2668854 prediction: [[2 2 2 0 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eeehoo\n",
      "step: 10 cost: 1.2404665 prediction: [[2 0 2 0 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehoo\n",
      "step: 11 cost: 1.2094775 prediction: [[2 0 2 0 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehoo\n",
      "step: 12 cost: 1.1760423 prediction: [[2 0 2 0 2 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: eheheo\n",
      "step: 13 cost: 1.1750063 prediction: [[2 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehho\n",
      "step: 14 cost: 1.1394972 prediction: [[2 0 2 0 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehoo\n",
      "step: 15 cost: 1.1327035 prediction: [[0 0 2 0 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehoo\n",
      "step: 16 cost: 1.1205357 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 17 cost: 1.1072294 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 18 cost: 1.1042497 prediction: [[0 0 2 0 2 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hheheo\n",
      "step: 19 cost: 1.107298 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 20 cost: 1.0944859 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 21 cost: 1.0891496 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 22 cost: 1.0853277 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 23 cost: 1.082595 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 24 cost: 1.080575 prediction: [[0 0 2 0 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehoo\n",
      "step: 25 cost: 1.0817766 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 26 cost: 1.0784644 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 27 cost: 1.0780611 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 28 cost: 1.0778028 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 29 cost: 1.0776364 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 30 cost: 1.0775084 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 31 cost: 1.0773684 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 32 cost: 1.077176 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 33 cost: 1.0769124 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 34 cost: 1.0765858 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 35 cost: 1.0762228 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 36 cost: 1.0758556 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 37 cost: 1.0755098 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 38 cost: 1.0752 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 39 cost: 1.0749315 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 40 cost: 1.0747062 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 41 cost: 1.0745233 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 42 cost: 1.0743688 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 43 cost: 1.0742382 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 44 cost: 1.0741273 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 45 cost: 1.0740329 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 46 cost: 1.0739521 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 47 cost: 1.0738823 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 48 cost: 1.0738219 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 49 cost: 1.0737693 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 50 cost: 1.0737234 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 51 cost: 1.0736828 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 52 cost: 1.0736469 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 53 cost: 1.0736152 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 54 cost: 1.0735867 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 55 cost: 1.0735612 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 56 cost: 1.0735382 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 57 cost: 1.0735174 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 58 cost: 1.0734987 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 59 cost: 1.0734817 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 60 cost: 1.073466 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 61 cost: 1.0734516 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 62 cost: 1.0734385 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 63 cost: 1.0734264 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 64 cost: 1.0734152 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 65 cost: 1.0734049 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 66 cost: 1.0733951 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 67 cost: 1.0733861 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 68 cost: 1.0733777 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 69 cost: 1.0733697 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 70 cost: 1.0733622 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 71 cost: 1.0733553 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 72 cost: 1.0733488 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 73 cost: 1.0733424 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 74 cost: 1.0733365 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 75 cost: 1.073331 prediction: [[0 0 2 0 4 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehoo\n",
      "step: 76 cost: 1.0735626 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 77 cost: 1.0733647 prediction: [[2 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: ehehho\n",
      "step: 78 cost: 1.0749351 prediction: [[0 0 2 2 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hheeho\n",
      "step: 79 cost: 1.0744107 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 80 cost: 1.0735205 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 81 cost: 1.0735669 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 82 cost: 1.0736123 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 83 cost: 1.0736569 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 84 cost: 1.0737005 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 85 cost: 1.0737464 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 86 cost: 1.0737907 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 87 cost: 1.0738329 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 88 cost: 1.0740372 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 89 cost: 1.0739034 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 90 cost: 1.0739295 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 91 cost: 1.0739506 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 92 cost: 1.0739667 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 93 cost: 1.0739776 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 94 cost: 1.0739833 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 95 cost: 1.0739843 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 96 cost: 1.0739805 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 97 cost: 1.0739726 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 98 cost: 1.0739609 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 99 cost: 1.0739461 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n",
      "step: 100 cost: 1.0739285 prediction: [[0 0 2 0 0 4]] true Y: [[1, 0, 2, 3, 3, 4]]\n",
      "predction str: hhehho\n"
     ]
    }
   ],
   "source": [
    "idx2char=['h', 'i', 'e', 'l', 'o']\n",
    "xdata=[[0,1,0,2,3,3]] # xdata=\"hihell\"\n",
    "                     #        \"ihello\"\n",
    "        #   cell -> ihello\n",
    "x_onehot=[[\n",
    "     [1,0,0,0,0],\n",
    "     [0,1,0,0,0],\n",
    "     [1,0,0,0,0],\n",
    "     [0,0,1,0,0],\n",
    "     [0,0,0,1,0],\n",
    "     [0,0,0,1,0]]]\n",
    "ydata=[[1,0,2,3,3,4]] #\"ihello\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes=5\n",
    "input_dim=5 #입력데이터의 차원(단어벡터의 길이)\n",
    "hidden_size=5\n",
    "batch_size=1\n",
    "sequence_length=6 #hihell\n",
    "learning_rate=0.1\n",
    "\n",
    "x=tf.placeholder(tf.float32, [None,sequence_length,input_dim])\n",
    "y=tf.placeholder(tf.int32, [None,sequence_length])\n",
    "\n",
    "cell=tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "ini_state=cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states=tf.nn.dynamic_rnn(cell, x, initial_state=ini_state, dtype=tf.float32)\n",
    "\n",
    "x_fc=tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs=tf.contrib.layers.fully_connected(inputs=x_fc, num_outputs=num_classes)\n",
    "outputs=tf.reshape(outputs, [batch_size,sequence_length,num_classes])\n",
    "#                           [1, 6, 5] =>[[[0.1,0.2,0.5,0.1,0.1] ],[ ],...,[ ]]\n",
    "\n",
    "weights=tf.ones([batch_size, sequence_length])\n",
    "sequence_loss=tf.contrib.seq2seq.sequence_loss(logits=outputs,targets=y, weights=weights)\n",
    "loss=tf.reduce_mean(sequence_loss)\n",
    "\n",
    "prediction=  tf.argmax(outputs,axis=2)\n",
    "\n",
    "train=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(101):\n",
    "        lv, _=sess.run([loss, train], \n",
    "                       feed_dict={x:x_onehot, y:ydata})\n",
    "        res=sess.run(prediction,feed_dict={x:x_onehot})\n",
    "        print(\"step:\",i,\"cost:\",lv, \"prediction:\", res, \n",
    "              \"true Y:\", ydata)\n",
    "        resStr=[idx2char[c] for c in np.squeeze(res)]\n",
    "        print(\"predction str:\",\"\".join(resStr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l', 'i', 'h', 'e', 'i']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=[[3,1,0,2,1]]\n",
    "# np.squeeze(test) # 차원 내려주는 함수\n",
    "test2=[idx2char [c] for c in np.squeeze(test)]\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import pprint \n",
    "tf.reset_default_graph() # session 만들기 전에 그래프 초기화하기\n",
    "pp=pprint.PrettyPrinter(indent=4)\n",
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=[1,0,0,0] # hello => 4글자\n",
    "e=[0,1,0,0]\n",
    "l=[0,0,1,0]\n",
    "o=[0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "array([[[0.680201  , 0.21927692]]], dtype=float32)\n",
      "array([[0.680201  , 0.21927692]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('first_cell') as scope:\n",
    "    hidden_size=2 # 2차원\n",
    "    cell=tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    print(cell.output_size, cell.state_size)\n",
    "    xdata=np.array([[h]], dtype=np.float32)\n",
    "    outputs,_states=tf.nn.dynamic_rnn(cell, xdata, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())\n",
    "    pp.pprint(_states.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]], dtype=float32)\n",
      "array([[[-0.4018405 ,  0.23028307,  0.381782  , -0.46824923,\n",
      "          0.12643304,  0.462466  ],\n",
      "        [-0.18211307,  0.33006454,  0.6119752 , -0.7052023 ,\n",
      "          0.42372483, -0.57520837],\n",
      "        [ 0.5645258 ,  0.736937  ,  0.22579458, -0.41114545,\n",
      "         -0.6542987 , -0.62958586],\n",
      "        [ 0.61032426,  0.29288793, -0.38336554,  0.19066586,\n",
      "         -0.667347  , -0.72544116],\n",
      "        [ 0.5200934 , -0.529092  , -0.81993884,  0.19085152,\n",
      "         -0.39565524,  0.12361063]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('sec_cell') as scope:\n",
    "    hidden_size=6 # 6차원 , 추출하고자 하는 특징\n",
    "    cell=tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    xdata=np.array([[h,e,l,l,o]], dtype=np.float32)\n",
    "    print(xdata.shape) # (1, 5, 4) =(batch_size,seq_length,input_dim)\n",
    "    pp.pprint(xdata)\n",
    "    outputs,_states=tf.nn.dynamic_rnn(cell, xdata, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "array([[[ 0.0197665 ,  0.5191908 ],\n",
      "        [-0.652543  , -0.2532097 ],\n",
      "        [ 0.27579546, -0.38055763],\n",
      "        [ 0.16919109, -0.47628978],\n",
      "        [ 0.0380247 ,  0.17428748]],\n",
      "\n",
      "       [[-0.33075398,  0.17651384],\n",
      "        [-0.36869687, -0.24236642],\n",
      "        [ 0.204504  , -0.44471413],\n",
      "        [ 0.23633698, -0.41989827],\n",
      "        [ 0.20963773, -0.44295737]],\n",
      "\n",
      "       [[-0.08040207, -0.646203  ],\n",
      "        [ 0.44242695, -0.20805171],\n",
      "        [-0.268038  ,  0.24035051],\n",
      "        [-0.44657096,  0.04269702],\n",
      "        [-0.01113443, -0.6023232 ]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('thr_cell') as scope:\n",
    "    hidden_size=2 # 2차원 , 추출하고자 하는 특징\n",
    "    cell=tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    xdata=np.array([[h,e,l,l,o],\n",
    "                   [e,o,l,l,l],\n",
    "                   [l,l,e,e,l]], dtype=np.float32)\n",
    "    print(xdata.shape) # (3, 5, 4) =(batch_size,seq_length,input_dim)\n",
    "    pp.pprint(xdata)\n",
    "    outputs,_states=tf.nn.dynamic_rnn(cell, xdata, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "array([[[-0.00645857,  0.06096779],\n",
      "        [ 0.14418894,  0.0480664 ],\n",
      "        [ 0.11326347, -0.17120096],\n",
      "        [ 0.15688924, -0.33632037],\n",
      "        [ 0.22947495, -0.35370985]],\n",
      "\n",
      "       [[ 0.15885071,  0.00111706],\n",
      "        [ 0.17092356, -0.15006763],\n",
      "        [ 0.19864793, -0.35254478],\n",
      "        [ 0.2301636 , -0.46135247],\n",
      "        [ 0.2575241 , -0.525177  ]],\n",
      "\n",
      "       [[ 0.05847339, -0.19343565],\n",
      "        [ 0.12273372, -0.34363112],\n",
      "        [ 0.31122842, -0.24834503],\n",
      "        [ 0.3651099 , -0.22102582],\n",
      "        [ 0.24124447, -0.40783525]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# M(시트),V(그래프),C(컨트롤러(막대)) 분리\n",
    "with tf.variable_scope('lstm_thr_cell') as scope:\n",
    "    hidden_size=2 # 2차원 , 추출하고자 하는 특징\n",
    "    cell=tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    xdata=np.array([[h,e,l,l,o],\n",
    "                   [e,o,l,l,l],\n",
    "                   [l,l,e,e,l]], dtype=np.float32)\n",
    "    print(xdata.shape) # (1, 5, 4) =(batch_size,seq_length,input_dim)\n",
    "    pp.pprint(xdata)\n",
    "    outputs,_states=tf.nn.dynamic_rnn(cell, xdata, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "array([[[ 0.0096851 ,  0.13529623],\n",
      "        [ 0.11435476,  0.03642866],\n",
      "        [ 0.06805395,  0.06833284],\n",
      "        [ 0.00590002,  0.09689396],\n",
      "        [ 0.12565891, -0.02646654]],\n",
      "\n",
      "       [[ 0.11113451, -0.06463631],\n",
      "        [ 0.19101495, -0.13958214],\n",
      "        [ 0.12195124, -0.11071184],\n",
      "        [ 0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ]],\n",
      "\n",
      "       [[-0.0471239 ,  0.0449914 ],\n",
      "        [-0.08238813,  0.08419165],\n",
      "        [ 0.07238495,  0.00109478],\n",
      "        [ 0.15266635, -0.06875317],\n",
      "        [ 0.        ,  0.        ]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('lstm_thr_cell_2') as scope:\n",
    "    hidden_size=2 # 2차원 , 추출하고자 하는 특징\n",
    "    cell=tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    xdata=np.array([[h,e,l,l,o],\n",
    "                   [e,o,l,l,l],\n",
    "                   [l,l,e,e,l]], dtype=np.float32)\n",
    "    print(xdata.shape) # (1, 5, 4) =(batch_size,seq_length,input_dim)\n",
    "    pp.pprint(xdata)\n",
    "    outputs,_states=tf.nn.dynamic_rnn(cell, xdata, sequence_length=[5,3,4],dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "array([[[-0.02525274,  0.07550837],\n",
      "        [-0.13323417, -0.00758323],\n",
      "        [ 0.02142371, -0.01214548],\n",
      "        [ 0.1080116 , -0.00365101],\n",
      "        [ 0.12789305, -0.09502799]],\n",
      "\n",
      "       [[-0.09014505, -0.03834355],\n",
      "        [-0.01866181, -0.11696686],\n",
      "        [ 0.08297458, -0.07268869],\n",
      "        [ 0.15771493, -0.03637911],\n",
      "        [ 0.20971847, -0.00682593]],\n",
      "\n",
      "       [[ 0.09065913,  0.00198483],\n",
      "        [ 0.15849572,  0.0109465 ],\n",
      "        [ 0.14155647, -0.01996978],\n",
      "        [ 0.05042074, -0.04210166],\n",
      "        [ 0.11948559, -0.01452091]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# weight 초기화\n",
    "with tf.variable_scope('init_lstm_thr_cell') as scope:\n",
    "    hidden_size=2 # 2차원 , 추출하고자 하는 특징\n",
    "    batch_size=3 # 3개 단위로 학습. 몇번 업데이트 할지\n",
    "    cell=tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)\n",
    "    xdata=np.array([[h,e,l,l,o],\n",
    "                   [e,o,l,l,l],\n",
    "                   [l,l,e,e,l]], dtype=np.float32)\n",
    "    print(xdata.shape) # (1, 5, 4) =(batch_size,seq_length,input_dim)\n",
    "    pp.pprint(xdata)\n",
    "    init_state=cell.zero_state(batch_size, tf.float32)\n",
    "    outputs,_states=tf.nn.dynamic_rnn(cell, xdata, initial_state=init_state,dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())\n",
    "    \n",
    "    #데이터 : 100개\n",
    "        #1에폭 : 100개 데이터를 학습\n",
    "    # batch_size:20개, batch_length:100/20=5번\n",
    "        #(20개 단위로 학습(forward, backward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]\n",
      "  [ 9 10 11]\n",
      "  [12 13 14]]\n",
      "\n",
      " [[15 16 17]\n",
      "  [18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]\n",
      "\n",
      " [[30 31 32]\n",
      "  [33 34 35]\n",
      "  [36 37 38]\n",
      "  [39 40 41]\n",
      "  [42 43 44]]]\n"
     ]
    }
   ],
   "source": [
    "batch_size=3 \n",
    "seq_len=5 #입력에 해당하는 글자의 수\n",
    "in_dim=3 # 각 문자의 shape 3\n",
    "xdata=np.arange(45).reshape(batch_size, seq_len, in_dim) #(3,5,3)\n",
    "print(xdata) # [0,1,2],[3,4,5],... 리스트 하나하나가 in_dim을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 에러 발생\n",
    "with tf.variable_scope('multi_rnn_cell') as scope:\n",
    "    \n",
    "    cell=tf.contrib.rnn.BasicLSTMCell(num_units=5) \n",
    "    cell=tf.contrib.rnn.MultiRNNCell([cell]*3) #layer 3개 \n",
    "    outputs,_states=tf.nn.dynamic_rnn(cell, xdata, dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 에러 발생\n",
    "# rnn에서 cost를 구하는 과정\n",
    "ydata=tf.constant([[1,1,1]])\n",
    "#        원래 값 : [[[0,1],[0,1],[0,1]]]\n",
    "#     소프트맥스에 넣으면 최대값 인덱스만 출력되서 [[1,1,1]] 출력\n",
    "\n",
    "prediction1=tf.constant([[[0.3,0.7],[0.1,0.9],[0.3,0.7]]]) # hidden_size=2, sequence_lentgh=3\n",
    "prediction2=tf.constant([[[0.4,0.6],[0.4,0.6],[0.6,0.4]]])\n",
    "\n",
    "loss1=tf.contrib.seq2seq.sequence_loss(prediction1, ydata)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(loss1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
