{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow_minist based CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist/data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist/data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"./mnist/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x=tf.placeholder(tf.float32, [None,28,28,1]) #4차원\n",
    "y=tf.placeholder(tf.float32, [None,10])\n",
    "keep_prob=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 정의\n",
    "w1=tf.Variable(tf.random_normal([3,3,1,32])) # 32개의 특성을 가지고 합성곱 연산\n",
    "# [3,3]:필터(커널)크기, 1:채널 특성 개수, 32:필터의 개수\n",
    "L1=tf.nn.conv2d(x,w1,strides=[1,1,1,1], padding=\"SAME\") #convolution\n",
    "# strides=[1(고정),1(칸),1(줄),1(고정)], padding=\"SAME\" : shape 유지\n",
    "L1=tf.nn.relu(L1)\n",
    "L1=tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "## X:[None,28,28,1]\n",
    "## w1:[3,3,1,32]\n",
    "## L1: CONV -> [None,28,28,32] \n",
    "## pooling -> [None, 14,14,32]\n",
    "# pooling은 반드시 해야하는 것은 아니고, 용도에 맞은 풀링을 사용하면 됨\n",
    "# ksize=kernel size [1(고정),적정한 값,적정한 값,1(고정)] => 보통 2칸씩 이동하긴하지만, 반드시 그럴 필요는 없음\n",
    "# ksize가 커질수록 정확도가 떨어짐\n",
    "\n",
    "w2=tf.Variable(tf.random_normal([3,3,32,64]))\n",
    "# [3,3]:필터(커널)크기, 32:채널 특성 개수, 64:필터의 개수\n",
    "L2=tf.nn.conv2d(L1,w2,strides=[1,1,1,1], padding=\"SAME\") #convolution\n",
    "L2=tf.nn.relu(L2)\n",
    "L2=tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1],padding=\"SAME\")\n",
    "# L2: CONV -> [None,14,14,64]\n",
    "# pooling -> [None,7,7,64]\n",
    "\n",
    "# FC 계층: 입력 7*7*64 => 출력 256\n",
    "w3=tf.Variable(tf.random_normal([7*7*64, 256]))\n",
    "L3=tf.reshape(L2,[-1,7*7*64]) # flatten:3차원 -> 1차원, -1 = None\n",
    "L3=tf.matmul(L3,w3) # 결과 shape : [-1,256]\n",
    "L3=tf.nn.relu(L3)\n",
    "L3=tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "w4=tf.Variable(tf.random_normal([256,10]))\n",
    "model=tf.matmul(L3,w4) # [None,10], 결과값이 점수(score)로 나옴, 예측값\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y))\n",
    "# score값이 확률값으로 변환되어, 원핫인코딩된 label과 곱해져 log를 취한 값이 출력되고 reduce_mean을 해주면\n",
    "# softmax cost 값으로 결과 출력\n",
    "optimizer=tf.train.AdamOptimizer(0.01).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭: 1 평균 cost: 211.893\n",
      "에폭: 2 평균 cost: 2.017\n",
      "에폭: 3 평균 cost: 1.826\n",
      "에폭: 4 평균 cost: 1.817\n",
      "에폭: 5 평균 cost: 1.743\n",
      "에폭: 6 평균 cost: 1.715\n",
      "에폭: 7 평균 cost: 1.661\n",
      "에폭: 8 평균 cost: 1.736\n",
      "에폭: 9 평균 cost: 1.757\n",
      "에폭: 10 평균 cost: 1.956\n",
      "모델 생성 완료\n",
      "정확도 :  0.4179\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size=100\n",
    "total_batch=int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_cost=0\n",
    "    \n",
    "    for i in range(total_batch): #600번(1에폭)\n",
    "        batch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
    "        batch_xs=batch_xs.reshape(-1,28,28,1)\n",
    "        _,cv=sess.run([optimizer, cost], feed_dict={x:batch_xs, \n",
    "                                                    y:batch_ys, \n",
    "                                                    keep_prob:0.7})\n",
    "        total_cost += cv\n",
    "        \n",
    "    print(\"에폭:\", \"%d\" % (epoch+1),\n",
    "          \"평균 cost:\",\"{:.3f}\".format(total_cost/total_batch))\n",
    "print(\"모델 생성 완료\")\n",
    "# 60000개 샘플 = 100 * 600\n",
    "\n",
    "is_correct= tf.equal(tf.argmax(model,1),tf.argmax(y,1))\n",
    "accuracy =tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={x:mnist.test.images.reshape(-1,28,28,1),\n",
    "                                             y:mnist.test.labels,\n",
    "                                             keep_prob:1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.layers 서브 패키지 활용한 CNN 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# 기본적으로 inputs, outputs size, kernel_size 만 넣어주면\n",
    "# 활성화 함수 적용은 물론, 컨볼루션 신경망을 만들기 위한 나머지 수치들은 알아서 계산해줍니다.\n",
    "# 특히 Weights 를 계산하는데 xavier_initializer 를 쓰고 있는 등,\n",
    "# 크게 신경쓰지 않아도 일반적으로 효율적인 신경망을 만들어줍니다.\n",
    "L1 = tf.layers.conv2d(X, 32, [3, 3], activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(L1, [2, 2], [2, 2])\n",
    "L1 = tf.layers.dropout(L1, 0.7, is_training)\n",
    "\n",
    "L2 = tf.layers.conv2d(L1, 64, [3, 3], activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(L2, [2, 2], [2, 2])\n",
    "L2 = tf.layers.dropout(L2, 0.7, is_training)\n",
    "\n",
    "L3 = tf.contrib.layers.flatten(L2)\n",
    "L3 = tf.layers.dense(L3, 256, activation=tf.nn.relu)\n",
    "L3 = tf.layers.dropout(L3, 0.5, is_training)\n",
    "\n",
    "model = tf.layers.dense(L3, 10, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.1788\n",
      "Epoch: 0002 Avg. cost = 0.0526\n",
      "Epoch: 0003 Avg. cost = 0.0368\n",
      "Epoch: 0004 Avg. cost = 0.0269\n",
      "Epoch: 0005 Avg. cost = 0.0199\n",
      "Epoch: 0006 Avg. cost = 0.0150\n",
      "Epoch: 0007 Avg. cost = 0.0126\n",
      "Epoch: 0008 Avg. cost = 0.0106\n",
      "Epoch: 0009 Avg. cost = 0.0076\n",
      "Epoch: 0010 Avg. cost = 0.0072\n",
      "Epoch: 0011 Avg. cost = 0.0060\n",
      "Epoch: 0012 Avg. cost = 0.0061\n",
      "Epoch: 0013 Avg. cost = 0.0051\n",
      "Epoch: 0014 Avg. cost = 0.0032\n",
      "Epoch: 0015 Avg. cost = 0.0054\n",
      "최적화 완료!\n",
      "정확도: 0.9916\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          is_training: True})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n",
    "                                   Y: mnist.test.labels,\n",
    "                                   is_training: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras에서 mnist CNN 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3차원으로 나온 결과를 1차원으로 출력해야함\n",
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "=================================================================\n",
      "Total params: 92,672\n",
      "Trainable params: 92,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images, test_labels)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape\n",
    "train_images=train_images.reshape((60000, 28, 28,1)) # 채널(색상) 추가\n",
    "train_images=train_images.astype('float32')/255\n",
    "test_images=test_images.reshape((10000, 28, 28,1)) # 채널(색상) 추가\n",
    "test_images=test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 15:09:25.395745  2452 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 15:09:52.930166  2452 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0819 15:09:53.015935  2452 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.1773 - acc: 0.94501s\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 27s 450us/step - loss: 0.0465 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 28s 459us/step - loss: 0.0326 - acc: 0.9903\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.0248 - acc: 0.9921\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.0192 - acc: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2098533ea90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 127us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9912"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc=model.evaluate(test_images, test_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# 원본 데이터셋을 압축 해제한 디렉터리 경로\n",
    "original_dataset_dir = 'data/dogs-vs-cats/train/'\n",
    "\n",
    "# 소규모 데이터셋을 저장할 디렉터리\n",
    "base_dir = 'data/dogs-vs-cats/cats_and_dogs_small'\n",
    "if os.path.exists(base_dir):  # 반복적인 실행을 위해 디렉토리를 삭제합니다.\n",
    "    shutil.rmtree(base_dir)   # 이 코드는 책에 포함되어 있지 않습니다.\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# 훈련용 고양이 사진 디렉터리\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "# 훈련용 강아지 사진 디렉터리\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "# 검증용 고양이 사진 디렉터리\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "# 검증용 강아지 사진 디렉터리\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# 테스트용 고양이 사진 디렉터리\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "\n",
    "# 테스트용 강아지 사진 디렉터리\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "# 처음 1,000개의 고양이 이미지를 train_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst) # src에 있는걸 dst로 복사하는 함수\n",
    "\n",
    "# 다음 500개 고양이 이미지를 validation_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 고양이 이미지를 test_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 강아지 이미지를 validation_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 강아지 이미지를 test_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(train_cats_dir))\n",
    "# 트레이닝 고양이, 강아지 각각 1000개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mission : 고양이, 강아지 분류기 제작\n",
    "#### 내일 : 연관규칙(apriori)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
